<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3">
    <Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0">
        <bitmap>media/images/box/root.png</bitmap>
        <script language="4">
            <content>
                <![CDATA[]]>
</content>
        </script>
        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
        <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
        <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
        <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
        <Timeline enable="0">
            <BehaviorLayer name="behavior_layer1">
                <BehaviorKeyframe name="keyframe1" index="1">
                    <Diagram scale="100">
                        <Box name="Say Text" id="2" localization="8" tooltip="Say the text received on its input." x="558" y="395">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Text Edit" id="3" localization="8" tooltip="Send the text you entered when the input is stimulated." plugin="textedit_plugin" x="69" y="284">
                            <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("What is your name")]]>
</content>
                            </script>
                            <pluginContent>
                                <text>
                                    <![CDATA[What is your name]]>
</text>
                            </pluginContent>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the text on the output." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The text you entered." id="3" />
                        </Box>
                        <Box name="Watson Say" id="4" localization="8" tooltip="This box makes the robot say whatever text is given to it, in the voice of Watson. This is done by using the Bluemix Text to Speech (TTS) service.&#x0A;&#x0A;Input: The string of text that you want Watson to say.&#x0A;&#x0A;Output: There is no box output, but this causes the robot to speak." x="503" y="41">
                            <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import os

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        if not os.path.exists('/home/nao/recordings/watson_tts/'):
            os.makedirs('/home/nao/recordings/watson_tts/')
        self.watson = ALProxy('ALWatson')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        self.watson.tts(p, None, None, None)
        self.onStopped() #activate the output of the box]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Input the text that you would like to hear Watson say; you can do this with a &apos;Text Edit&apos; box. You can also use a &apos;Watson Listening&apos; box if you speak in English." id="2" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="A signal sent when box behavior is finished, and the robot speaks the given text." id="3" />
                        </Box>
                        <Box name="English to Spanish" id="1" localization="8" tooltip="Translate English text to Spanish text by using the Bluemix Machine Translation service. By using this box, the robot&apos;s language is set to Spanish.&#x0A;&#x0A;Input: A string of English text to be translated&#x0A;&#x0A;Output: The string of text in Spanish" x="340" y="245">
                            <bitmap>media/images/box/watson-lib-icons/translation_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.watson = ALProxy('ALWatson')
        self.tts = ALProxy('ALTextToSpeech')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        try:
            translation = self.watson.translate(p,'English','Spanish',None,None)
            self.tts.setLanguage('Spanish')
            self.onStopped(translation) #activate the output of the box

        except Exception as err:
            self.logger.warning(err)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="An English sentence that you want to translate. You can do this with a &apos;Text Edit&apos; box, or with a &apos;Watson Listening&apos; box." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="The Spanish translation of the English sentence. The robot is also set to Spanish." id="3" />
                        </Box>
                        <Box name="English to Portuguese" id="6" localization="8" tooltip="This box translates English text to Portuguese text by using the Bluemix Machine Translation service. By using this box, the robot&apos;s language is set to Portuguese.&#x0A;&#x0A;Input: A string of English text to be translated&#x0A;&#x0A;Output: The string of text in Portuguese&#x0A;&#x0A;NOTE: There is no current support for a Portuguese Language pack, so this uses a Spanish pronounciation guide for now." x="340" y="338">
                            <bitmap>media/images/box/watson-lib-icons/translation_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.watson = ALProxy('ALWatson')
        self.tts = ALProxy('ALTextToSpeech')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        try:
            translation = self.watson.translate(p,'English','Portuguese',None,None)
            self.tts.setLanguage('Spanish')
            self.onStopped(translation) #activate the output of the box

        except Exception as err:
            self.logger.warning(err)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="An English sentence that you want to translate. You can do this with a &apos;Text Edit&apos; box, or with a &apos;Watson Listening&apos; box." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="The Portuguese translation of the English sentence. The robot is also set to Portuguese." id="3" />
                        </Box>
                        <Box name="French to English" id="11" localization="8" tooltip="This box translates French text to English text by using the Bluemix Machine Translation service. By using this box, the robot&apos;s language is set to English.&#x0A;&#x0A;Input: A string of French text to be translated&#x0A;&#x0A;Output: The string of text in English" x="340" y="431">
                            <bitmap>media/images/box/watson-lib-icons/translation_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.watson = ALProxy('ALWatson')
        self.tts = ALProxy('ALTextToSpeech')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        try:
            translation = self.watson.translate(p,'French','English',None,None)
            self.tts.setLanguage('English')
            self.onStopped(translation) #activate the output of the box

        except Exception as err:
            self.logger.warning(err)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="A French sentence that you want to translate. You can do this with a &apos;Text Edit&apos; box." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="The English translation of the French sentence. The robot is also set to English." id="3" />
                        </Box>
                        <Box name="Spanish to English" id="9" localization="8" tooltip="This box translates Spanish text to English text by using the Bluemix Machine Translation service. By using this box, the robot&apos;s language is set to English.&#x0A;&#x0A;Input: A string of Spanish text to be translated&#x0A;&#x0A;Output: The string of text in English" x="340" y="524">
                            <bitmap>media/images/box/watson-lib-icons/translation_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.watson = ALProxy('ALWatson')
        self.tts = ALProxy('ALTextToSpeech')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        try:
            translation = self.watson.translate(p,'Spanish','English',None,None)
            self.tts.setLanguage('English')
            self.onStopped(translation) #activate the output of the box

        except Exception as err:
            self.logger.warning(err)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="A Spanish sentence that you want to translate. You can do this with a &apos;Text Edit&apos; box." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="The English translation of the Spanish sentence. The robot is also set to English." id="3" />
                        </Box>
                        <Box name="Portuguese to English" id="14" localization="8" tooltip="This box translates Portuguese text to English text by using the Bluemix Machine Translation service. By using this box, the robot&apos;s language is set to English.&#x0A;&#x0A;Input: A string of Portuguese text to be translated&#x0A;&#x0A;Output: The string of text in English" x="340" y="617">
                            <bitmap>media/images/box/watson-lib-icons/translation_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.watson = ALProxy('ALWatson')
        self.tts = ALProxy('ALTextToSpeech')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        try:
            translation = self.watson.translate(p,'Portuguese','English',None,None)
            self.tts.setLanguage('English')
            self.onStopped(translation) #activate the output of the box

        except Exception as err:
            self.logger.warning(err)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="A Portuguese sentence that you want to translate. You can do this with a &apos;Text Edit&apos; box." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="The English translation of the Portuguese sentence. The robot is also set to English." id="3" />
                        </Box>
                        <Box name="Arabic to English" id="18" localization="8" tooltip="This box translates Arabic text to English text by using the Bluemix Machine Translation service. By using this box, the robot&apos;s language is set to English.&#x0A;&#x0A;Input: A string of Arabic text to be translated&#x0A;&#x0A;Output: The string of text in English" x="340" y="710">
                            <bitmap>media/images/box/watson-lib-icons/translation_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.watson = ALProxy('ALWatson')
        self.tts = ALProxy('ALTextToSpeech')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        try:
            translation = self.watson.translate(p,'Arabic','English',None,None)
            self.tts.setLanguage('English')
            self.onStopped(translation) #activate the output of the box

        except Exception as err:
            self.logger.warning(err)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="An Arabic sentence that you want to translate. You can do this with a &apos;Text Edit&apos; box." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="The English translation of the Arabic sentence. The robot is also set to English." id="3" />
                        </Box>
                        <Box name="Universal Translator" id="16" localization="8" tooltip="This box translates text to another supported language by using the Bluemix Machine Translation service. By using this box, the robot&apos;s language is set to the destination language.&#x0A;&#x0A;Input: A string of text to be translated&#x0A;&#x0A;Output: The string of text in the desired  language&#x0A;&#x0A;NOTE: There is currently no Portuguese Language Pack, so if Portuguese is the destination, it will use Spanish as a pronouciation guide." x="340" y="803">
                            <bitmap>media/images/box/watson-lib-icons/translation_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.watson = ALProxy('ALWatson')
        self.tts = ALProxy('ALTextToSpeech')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        if self.getParameter("Translate From") == self.getParameter("Translate To"):
            #don't need to do a translation
            try:
                self.tts.setLanguage(self.getParameter("Translate To"))
                self.onStopped(p) #activate the output of the box

            except Exception as err:
                self.logger.warning(err)

        elif not ((self.getParameter("Translate From") == "English") or (self.getParameter("Translate To") == "English")):
            #if neither is english, we need to do a two step translation thru english
            try:
                in_english = self.watson.translate(p,self.getParameter("Translate From"),'English',None,None)
                translation = self.watson.translate(in_english,'English',self.getParameter("Translate To"),None,None)
                self.tts.setLanguage(self.getParameter("Translate To"))
                self.onStopped(translation) #activate the output of the box

            except Exception as err:
                self.logger.warning(err)

        else:
            #else, it is a simple two step translation
            try:
                translation = self.watson.translate(p,self.getParameter("Translate From"),self.getParameter("Translate To"),None,None)
                self.tts.setLanguage(self.getParameter("Translate To"))
                self.onStopped(translation) #activate the output of the box

            except Exception as err:
                self.logger.warning(err)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="A sentence that you want to translate. You can do this with a &apos;Text Edit&apos; box, or with &apos;Watson Listening&apos; if your input language is English." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="The translation of the given sentence into the desired language. The robot is also set to destination language." id="3" />
                            <Parameter name="Translate From" inherits_from_parent="0" content_type="3" value="English" default_value="English" custom_choice="0" tooltip="Specifies the source language, or the language of the input text." id="4">
                                <Choice value="English" />
                                <Choice value="Spanish" />
                                <Choice value="Portuguese" />
                                <Choice value="French" />
                                <Choice value="Arabic" />
                            </Parameter>
                            <Parameter name="Translate To" inherits_from_parent="0" content_type="3" value="French" default_value="French" custom_choice="0" tooltip="Specifies the target language, or the language of the output text." id="5">
                                <Choice value="English" />
                                <Choice value="Spanish" />
                                <Choice value="French" />
                                <Choice value="Portuguese" />
                            </Parameter>
                        </Box>
                        <Box name="English to French" id="7" localization="8" tooltip="This box translates English text to French text by using the Bluemix Machine Translation service. By using this box, the robot&apos;s language is set to French.&#x0A;&#x0A;Input: A string of English text to be translated&#x0A;&#x0A;Output: The string of text in French" x="339" y="152">
                            <bitmap>media/images/box/watson-lib-icons/translation_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.watson = ALProxy('ALWatson')
        self.tts = ALProxy('ALTextToSpeech')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        try:
            translation = self.watson.translate(p,'English','French',None,None)
            self.tts.setLanguage('French')
            self.onStopped(translation) #activate the output of the box

        except Exception as err:
            self.logger.warning(err)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="An English sentence that you want to translate. You can do this with a &apos;Text Edit&apos; box, or with a &apos;Watson Listening&apos; box." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="The French translation of the English sentence. The robot is also set to French." id="3" />
                        </Box>
                        <Box name="Text Edit (1)" id="8" localization="8" tooltip="Send the text you entered when the input is stimulated." plugin="textedit_plugin" x="68" y="372">
                            <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("Quel est votre nom")]]>
</content>
                            </script>
                            <pluginContent>
                                <text>
                                    <![CDATA[Quel est votre nom]]>
</text>
                            </pluginContent>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the text on the output." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The text you entered." id="3" />
                        </Box>
                        <Box name="Text Edit (2)" id="10" localization="8" tooltip="Send the text you entered when the input is stimulated." plugin="textedit_plugin" x="68" y="461">
                            <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("Cuál es su nombre")]]>
</content>
                            </script>
                            <pluginContent>
                                <text>
                                    <![CDATA[Cuál es su nombre]]>
</text>
                            </pluginContent>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the text on the output." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The text you entered." id="3" />
                        </Box>
                        <Box name="Text Edit (3)" id="12" localization="8" tooltip="Send the text you entered when the input is stimulated." plugin="textedit_plugin" x="73" y="552">
                            <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("Qual é o seu nome")]]>
</content>
                            </script>
                            <pluginContent>
                                <text>
                                    <![CDATA[Qual é o seu nome]]>
</text>
                            </pluginContent>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the text on the output." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The text you entered." id="3" />
                        </Box>
                        <Box name="Text Edit (4)" id="13" localization="8" tooltip="Send the text you entered when the input is stimulated." plugin="textedit_plugin" x="74" y="638">
                            <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("ما اسمك")]]>
</content>
                            </script>
                            <pluginContent>
                                <text>
                                    <![CDATA[ما اسمك]]>
</text>
                            </pluginContent>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the text on the output." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The text you entered." id="3" />
                        </Box>
                        <Box name="Text Edit (5)" id="15" localization="8" tooltip="Send the text you entered when the input is stimulated." plugin="textedit_plugin" x="74" y="737">
                            <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("Hello my name is NAO")]]>
</content>
                            </script>
                            <pluginContent>
                                <text>
                                    <![CDATA[Hello my name is NAO]]>
</text>
                            </pluginContent>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the text on the output." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The text you entered." id="3" />
                        </Box>
                        <Box name="Personality Insights" id="17" localization="8" tooltip="This box uses Personality Insights, the Bluemix service designed to identify the personality of a person by analyzing a block of text written/spoken by the person. Personality Insights requires a minimum of 100 words, but suggests upwords of 2000 words.&#x0A;&#x0A;Input: The block of English text used to analyze a personality. Minimun 100 words, but 2000+ words suggested.&#x0A;&#x0A;Output: The raw json file which holds the analysis." x="354" y="1001">
                            <bitmap>media/images/box/watson-lib-icons/log_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[#import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.watson = ALProxy('ALWatson')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        pi = self.watson.personality(p,None,None)
        #Debug to see json in logger
        #self.logger.info(json.dumps(pi, sort_keys=True, indent=4, separators=(',', ': ')))
        self.onStopped(pi) #activate the output of the box
        pass]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Input the block of English text used to analyze a personality. Need at least 100 words, but for best results, Bluemix suggests at least 2000 words." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="A large data file (json) is the output of this box. This file holds personailty traits and their corresponding percentages; this shows how applicable they are to the given personality" id="3" />
                        </Box>
                        <Box name="Tradeoff Analytics" id="19" localization="8" tooltip="This box uses Tradeoff Analytics to help pick the best options among several choices. The Bluemix service is designed to accept an advanced json that has options, constraints, weights, and more to consider when optimizing for the best decision.&#x0A;&#x0A;Input: A json is used as input in the form of a string. The format for this is too long to list here, but further documentation for this can be found on the Bluemix site: http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/tradeoff-analytics.html&#x0A;&#x0A;Output: A similarly complex raw json is the output for the service. Documentation can also be found on the site listed above." x="354" y="1100">
                            <bitmap>media/images/box/watson-lib-icons/log_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[#import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.watson = ALProxy('ALWatson')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        tradeoffs = self.watson.tradeoff(p,None,None)
        #Debug to see json in logger
        #self.logger.info(json.dumps(tradeoffs, sort_keys=True, indent=4, separators=(',', ': ')))
        self.onStopped(tradeoffs) #activate the output of the box
        pass]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip=" A complex json is used as input. It is inputted as a string rather than a file. The documentation is too complex to list here, but  http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/tradeoff-analytics.html" id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip=" A  complex raw json is the output for the service. Further documentation can be found at http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/tradeoff-analytics.html" id="3" />
                        </Box>
                        <Box name="Say Text (1)" id="21" localization="8" tooltip="Say the text received on its input." x="509" y="916">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Text Edit (6)" id="22" localization="8" tooltip="Send the text you entered when the input is stimulated." plugin="textedit_plugin" x="83" y="842">
                            <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped(" Vice President Johnson, Mr. Speaker, Mr. Chief Justice, President Eisenhower, Vice President Nixon, President Truman, Reverend Clergy, fellow citizens:\n\n      We observe today not a victory of party but a celebration of freedom--symbolizing an end as well as a beginning--signifying renewal as well as change. For I have sworn before you and Almighty God the same solemn oath our forbears prescribed nearly a century and three-quarters ago.\n\n     The world is very different now. For man holds in his mortal hands the power to abolish all forms of human poverty and all forms of human life. And yet the same revolutionary beliefs for which our forebears fought are still at issue around the globe--the belief that the rights of man come not from the generosity of the state but from the hand of God.\n\n     We dare not forget today that we are the heirs of that first revolution. Let the word go forth from this time and place, to friend and foe alike, that the torch has been passed to a new generation of Americans--born in this century, tempered by war, disciplined by a hard and bitter peace, proud of our ancient heritage--and unwilling to witness or permit the slow undoing of those human rights to which this nation has always been committed, and to which we are committed today at home and around the world.\n\n     Let every nation know, whether it wishes us well or ill, that we shall pay any price, bear any burden, meet any hardship, support any friend, oppose any foe to assure the survival and the success of liberty.\n\n     This much we pledge--and more.\n\n     To those old allies whose cultural and spiritual origins we share, we pledge the loyalty of faithful friends. United there is little we cannot do in a host of cooperative ventures. Divided there is little we can do--for we dare not meet a powerful challenge at odds and split asunder.\n\n     To those new states whom we welcome to the ranks of the free, we pledge our word that one form of colonial control shall not have passed away merely to be replaced by a far more iron tyranny. We shall not always expect to find them supporting our view. But we shall always hope to find them strongly supporting their own freedom--and to remember that, in the past, those who foolishly sought power by riding the back of the tiger ended up inside.\n\n     To those people in the huts and villages of half the globe struggling to break the bonds of mass misery, we pledge our best efforts to help them help themselves, for whatever period is required--not because the communists may be doing it, not because we seek their votes, but because it is right. If a free society cannot help the many who are poor, it cannot save the few who are rich.\n\n     To our sister republics south of our border, we offer a special pledge--to convert our good words into good deeds--in a new alliance for progress--to assist free men and free governments in casting off the chains of poverty. But this peaceful revolution of hope cannot become the prey of hostile powers. Let all our neighbors know that we shall join with them to oppose aggression or subversion anywhere in the Americas. And let every other power know that this Hemisphere intends to remain the master of its own house.\n\n     To that world assembly of sovereign states, the United Nations, our last best hope in an age where the instruments of war have far outpaced the instruments of peace, we renew our pledge of support--to prevent it from becoming merely a forum for invective--to strengthen its shield of the new and the weak--and to enlarge the area in which its writ may run.\n\n     Finally, to those nations who would make themselves our adversary, we offer not a pledge but a request: that both sides begin anew the quest for peace, before the dark powers of destruction unleashed by science engulf all humanity in planned or accidental self-destruction.\n\n     We dare not tempt them with weakness. For only when our arms are sufficient beyond doubt can we be certain beyond doubt that they will never be employed.\n\n     But neither can two great and powerful groups of nations take comfort from our present course--both sides overburdened by the cost of modern weapons, both rightly alarmed by the steady spread of the deadly atom, yet both racing to alter that uncertain balance of terror that stays the hand of mankind\'s final war.\n\n     So let us begin anew--remembering on both sides that civility is not a sign of weakness, and sincerity is always subject to proof. Let us never negotiate out of fear. But let us never fear to negotiate.\n\n     Let both sides explore what problems unite us instead of belaboring those problems which divide us.\n\n     Let both sides, for the first time, formulate serious and precise proposals for the inspection and control of arms--and bring the absolute power to destroy other nations under the absolute control of all nations.\n\n     Let both sides seek to invoke the wonders of science instead of its terrors. Together let us explore the stars, conquer the deserts, eradicate disease, tap the ocean depths and encourage the arts and commerce.\n\n     Let both sides unite to heed in all corners of the earth the command of Isaiah--to \"undo the heavy burdens . . . (and) let the oppressed go free.\"\n\n     And if a beachhead of cooperation may push back the jungle of suspicion, let both sides join in creating a new endeavor, not a new balance of power, but a new world of law, where the strong are just and the weak secure and the peace preserved.\n\n     All this will not be finished in the first one hundred days. Nor will it be finished in the first one thousand days, nor in the life of this Administration, nor even perhaps in our lifetime on this planet. But let us begin.\n\n     In your hands, my fellow citizens, more than mine, will rest the final success or failure of our course. Since this country was founded, each generation of Americans has been summoned to give testimony to its national loyalty. The graves of young Americans who answered the call to service surround the globe.\n\n     Now the trumpet summons us again--not as a call to bear arms, though arms we need--not as a call to battle, though embattled we are-- but a call to bear the burden of a long twilight struggle, year in and year out, \"rejoicing in hope, patient in tribulation\"--a struggle against the common enemies of man: tyranny, poverty, disease and war itself.\n\n     Can we forge against these enemies a grand and global alliance, North and South, East and West, that can assure a more fruitful life for all mankind? Will you join in that historic effort?\n\n     In the long history of the world, only a few generations have been granted the role of defending freedom in its hour of maximum danger. I do not shrink from this responsibility--I welcome it. I do not believe that any of us would exchange places with any other people or any other generation. The energy, the faith, the devotion which we bring to this endeavor will light our country and all who serve it--and the glow from that fire can truly light the world.\n\n     And so, my fellow Americans: ask not what your country can do for you--ask what you can do for your country.\n\n     My fellow citizens of the world: ask not what America will do for you, but what together we can do for the freedom of man.\n\n     Finally, whether you are citizens of America or citizens of the world, ask of us here the same high standards of strength and sacrifice which we ask of you. With a good conscience our only sure reward, with history the final judge of our deeds, let us go forth to lead the land we love, asking His blessing and His help, but knowing that here on earth God\'s work must truly be our own. \n")]]>
</content>
                            </script>
                            <pluginContent>
                                <text>
                                    <![CDATA[ Vice President Johnson, Mr. Speaker, Mr. Chief Justice, President Eisenhower, Vice President Nixon, President Truman, Reverend Clergy, fellow citizens:

      We observe today not a victory of party but a celebration of freedom--symbolizing an end as well as a beginning--signifying renewal as well as change. For I have sworn before you and Almighty God the same solemn oath our forbears prescribed nearly a century and three-quarters ago.

     The world is very different now. For man holds in his mortal hands the power to abolish all forms of human poverty and all forms of human life. And yet the same revolutionary beliefs for which our forebears fought are still at issue around the globe--the belief that the rights of man come not from the generosity of the state but from the hand of God.

     We dare not forget today that we are the heirs of that first revolution. Let the word go forth from this time and place, to friend and foe alike, that the torch has been passed to a new generation of Americans--born in this century, tempered by war, disciplined by a hard and bitter peace, proud of our ancient heritage--and unwilling to witness or permit the slow undoing of those human rights to which this nation has always been committed, and to which we are committed today at home and around the world.

     Let every nation know, whether it wishes us well or ill, that we shall pay any price, bear any burden, meet any hardship, support any friend, oppose any foe to assure the survival and the success of liberty.

     This much we pledge--and more.

     To those old allies whose cultural and spiritual origins we share, we pledge the loyalty of faithful friends. United there is little we cannot do in a host of cooperative ventures. Divided there is little we can do--for we dare not meet a powerful challenge at odds and split asunder.

     To those new states whom we welcome to the ranks of the free, we pledge our word that one form of colonial control shall not have passed away merely to be replaced by a far more iron tyranny. We shall not always expect to find them supporting our view. But we shall always hope to find them strongly supporting their own freedom--and to remember that, in the past, those who foolishly sought power by riding the back of the tiger ended up inside.

     To those people in the huts and villages of half the globe struggling to break the bonds of mass misery, we pledge our best efforts to help them help themselves, for whatever period is required--not because the communists may be doing it, not because we seek their votes, but because it is right. If a free society cannot help the many who are poor, it cannot save the few who are rich.

     To our sister republics south of our border, we offer a special pledge--to convert our good words into good deeds--in a new alliance for progress--to assist free men and free governments in casting off the chains of poverty. But this peaceful revolution of hope cannot become the prey of hostile powers. Let all our neighbors know that we shall join with them to oppose aggression or subversion anywhere in the Americas. And let every other power know that this Hemisphere intends to remain the master of its own house.

     To that world assembly of sovereign states, the United Nations, our last best hope in an age where the instruments of war have far outpaced the instruments of peace, we renew our pledge of support--to prevent it from becoming merely a forum for invective--to strengthen its shield of the new and the weak--and to enlarge the area in which its writ may run.

     Finally, to those nations who would make themselves our adversary, we offer not a pledge but a request: that both sides begin anew the quest for peace, before the dark powers of destruction unleashed by science engulf all humanity in planned or accidental self-destruction.

     We dare not tempt them with weakness. For only when our arms are sufficient beyond doubt can we be certain beyond doubt that they will never be employed.

     But neither can two great and powerful groups of nations take comfort from our present course--both sides overburdened by the cost of modern weapons, both rightly alarmed by the steady spread of the deadly atom, yet both racing to alter that uncertain balance of terror that stays the hand of mankind's final war.

     So let us begin anew--remembering on both sides that civility is not a sign of weakness, and sincerity is always subject to proof. Let us never negotiate out of fear. But let us never fear to negotiate.

     Let both sides explore what problems unite us instead of belaboring those problems which divide us.

     Let both sides, for the first time, formulate serious and precise proposals for the inspection and control of arms--and bring the absolute power to destroy other nations under the absolute control of all nations.

     Let both sides seek to invoke the wonders of science instead of its terrors. Together let us explore the stars, conquer the deserts, eradicate disease, tap the ocean depths and encourage the arts and commerce.

     Let both sides unite to heed in all corners of the earth the command of Isaiah--to "undo the heavy burdens . . . (and) let the oppressed go free."

     And if a beachhead of cooperation may push back the jungle of suspicion, let both sides join in creating a new endeavor, not a new balance of power, but a new world of law, where the strong are just and the weak secure and the peace preserved.

     All this will not be finished in the first one hundred days. Nor will it be finished in the first one thousand days, nor in the life of this Administration, nor even perhaps in our lifetime on this planet. But let us begin.

     In your hands, my fellow citizens, more than mine, will rest the final success or failure of our course. Since this country was founded, each generation of Americans has been summoned to give testimony to its national loyalty. The graves of young Americans who answered the call to service surround the globe.

     Now the trumpet summons us again--not as a call to bear arms, though arms we need--not as a call to battle, though embattled we are-- but a call to bear the burden of a long twilight struggle, year in and year out, "rejoicing in hope, patient in tribulation"--a struggle against the common enemies of man: tyranny, poverty, disease and war itself.

     Can we forge against these enemies a grand and global alliance, North and South, East and West, that can assure a more fruitful life for all mankind? Will you join in that historic effort?

     In the long history of the world, only a few generations have been granted the role of defending freedom in its hour of maximum danger. I do not shrink from this responsibility--I welcome it. I do not believe that any of us would exchange places with any other people or any other generation. The energy, the faith, the devotion which we bring to this endeavor will light our country and all who serve it--and the glow from that fire can truly light the world.

     And so, my fellow Americans: ask not what your country can do for you--ask what you can do for your country.

     My fellow citizens of the world: ask not what America will do for you, but what together we can do for the freedom of man.

     Finally, whether you are citizens of America or citizens of the world, ask of us here the same high standards of strength and sacrifice which we ask of you. With a good conscience our only sure reward, with history the final judge of our deeds, let us go forth to lead the land we love, asking His blessing and His help, but knowing that here on earth God's work must truly be our own. 
]]>
</text>
                            </pluginContent>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the text on the output." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The text you entered." id="3" />
                        </Box>
                        <Box name="Text Edit (7)" id="23" localization="8" tooltip="Send the text you entered when the input is stimulated." plugin="textedit_plugin" x="86" y="1138">
                            <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("{\n  \"subject\": \"phone\",\n  \"columns\": [\n    {\n      \"key\": \"price\",\n      \"type\": \"numeric\",\n      \"goal\": \"min\",\n      \"full_name\": \"Price\",\n      \"is_objective\": true,\n      \"format\": \"€####0.00\"\n    },\n    {\n      \"key\": \"brand\",\n      \"type\": \"categorical\",\n      \"goal\": \"min\",\n      \"full_name\": \"Brand\",\n      \"is_objective\": true,\n      \"range\": [\n        \"Samsung\",\n        \"Apple\",\n        \"HTC\",\n        \"LG\",\n        \"Nokia\",\n        \"Sony\"\n      ],\n      \"preference\": [\n        \"Samsung\",\n        \"Apple\",\n        \"HTC\",\n        \"LG\",\n        \"Nokia\",\n        \"Sony\"\n      ]\n    },\n    {\n      \"key\": \"RAM\",\n      \"type\": \"text\",\n      \"goal\": \"max\",\n      \"full_name\": \"RAM (MB)\",\n      \"is_objective\": false\n    },\n    {\n      \"key\": \"screen_size\",\n      \"type\": \"numeric\",\n      \"goal\": \"max\",\n      \"full_name\": \"Screen (inch)\",\n      \"is_objective\": true\n    },\n    {\n      \"key\": \"camera\",\n      \"type\": \"numeric\",\n      \"goal\": \"max\",\n      \"full_name\": \"Camera\",\n      \"is_objective\": false,\n      \"format\": \"####0 MP\"\n    },\n    {\n      \"key\": \"memory_size\",\n      \"type\": \"numeric\",\n      \"goal\": \"max\",\n      \"full_name\": \"Memory\",\n      \"is_objective\": false,\n      \"format\": \"####0 GB\"\n    },\n    {\n      \"key\": \"battery\",\n      \"type\": \"numeric\",\n      \"goal\": \"max\",\n      \"full_name\": \"Battery (mAh)\",\n      \"is_objective\": false\n    },\n    {\n      \"key\": \"weight\",\n      \"type\": \"numeric\",\n      \"goal\": \"min\",\n      \"full_name\": \"Weight\",\n      \"is_objective\": true,\n      \"format\": \"####0 g\"\n    },\n    {\n      \"key\": \"rDate\",\n      \"type\": \"datetime\",\n      \"goal\": \"max\",\n      \"full_name\": \"Release Date\",\n      \"is_objective\": false\n    }\n  ],\n  \"options\": [\n    {\n      \"key\": \" 1\",\n      \"name\": \"Samsung Galaxy S4 White\",\n      \"values\": {\n        \"weight\": 130,\n        \"price\": 239,\n        \"RAM\": 2048,\n        \"battery\": 2600,\n        \"camera\": 13,\n        \"memory_size\": 16,\n        \"screen_size\": 5,\n        \"brand\": \"Samsung\",\n        \"rDate\": \"2013-04-29T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Samsung_GALAXY_S4_zoom_%28White%29.jpg/800px-Samsung_GALAXY_S4_zoom_%28White%29.jpg\'/> <a title=\'Photo by Samsung Belgium (Flickr: GALAXY S4 zoom (1)) [CC BY 2.0 (http://creativecommons.org/licenses/by/2.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:Samsung_GALAXY_S4_zoom_(White).jpg\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    },\n    {\n      \"key\": \"2\",\n      \"name\": \"Samsung Galaxy S4 Black\",\n      \"values\": {\n        \"weight\": 130,\n        \"price\": 239,\n        \"RAM\": 2048,\n        \"battery\": 2600,\n        \"camera\": 13,\n        \"memory_size\": 16,\n        \"screen_size\": 5,\n        \"brand\": \"Samsung\",\n        \"rDate\": \"2013-04-29T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Samsung_Galaxy_S4.jpg/200px-Samsung_Galaxy_S4.jpg\'/><a title=\'Photo by Karlis Dambrans (Flickr: Samsung Galaxy S4) [CC BY 2.0 (http://creativecommons.org/licenses/by/2.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:Samsung_Galaxy_S4.jpg\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    },\n    {\n      \"key\": \"3\",\n      \"name\": \"Samsung Galaxy S3 White\",\n      \"values\": {\n        \"weight\": 133,\n        \"price\": 79,\n        \"RAM\": 2048,\n        \"battery\": 2100,\n        \"camera\": 8,\n        \"memory_size\": 16,\n        \"screen_size\": 4.8,\n        \"brand\": \"Samsung\",\n        \"rDate\": \"2012-05-29T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Samsung_Galaxy_S_III.png/300px-Samsung_Galaxy_S_III.png\'/> <a title=\'Photo by GalaxyOptimus (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:Samsung_Galaxy_S_III.png\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    },\n    {\n      \"key\": \"4\",\n      \"name\": \"Samsung Galaxy S3 Blue\",\n      \"values\": {\n        \"weight\": 133,\n        \"price\": 79,\n        \"RAM\": 2048,\n        \"battery\": 2100,\n        \"camera\": 8,\n        \"memory_size\": 16,\n        \"screen_size\": 4.8,\n        \"brand\": \"Samsung\",\n        \"rDate\": \"2012-05-29T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Samsung_Galaxy_S_Advance_i9070.JPG/250px-Samsung_Galaxy_S_Advance_i9070.JPG\'/> <a title=\'Photo by Macs79 (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:Samsung_Galaxy_S_Advance_i9070.JPG\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    },\n    {\n      \"key\": \"5\",\n      \"name\": \"Samsung Galaxy S3 mini White\",\n      \"values\": {\n        \"weight\": 111,\n        \"price\": 299,\n        \"RAM\": 1024,\n        \"battery\": 1000,\n        \"camera\": 5,\n        \"memory_size\": 8,\n        \"screen_size\": 4,\n        \"brand\": \"Samsung\",\n        \"rDate\": \"2012-10-01T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Samsung_Galaxy_S_III_mini.png/300px-Samsung_Galaxy_S_III_mini.png\'/> <a title=\'Photo by GalaxyOptimus (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:Samsung_Galaxy_S_III_mini.png\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    },\n    {\n      \"key\": \"6\",\n      \"name\": \"Apple iPhone 5 White\",\n      \"values\": {\n        \"weight\": 112,\n        \"price\": 449,\n        \"RAM\": 1024,\n        \"battery\": 1440,\n        \"camera\": 8,\n        \"memory_size\": 32,\n        \"screen_size\": 4,\n        \"brand\": \"Apple\",\n        \"rDate\": \"2012-09-21T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/9/9d/IPhone5white.png/228px-IPhone5white.png\'/> <a title=\'Photo by Pixeden.com [CC BY 3.0 (http://creativecommons.org/licenses/by/3.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:IPhone5white.png\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    },\n    {\n      \"key\": \"7\",\n      \"name\": \"Apple iPhone 5 Black\",\n      \"values\": {\n        \"weight\": 112,\n        \"price\": 449,\n        \"RAM\": 1024,\n        \"battery\": 1440,\n        \"camera\": 8,\n        \"memory_size\": 32,\n        \"screen_size\": 4,\n        \"brand\": \"Apple\",\n        \"rDate\": \"2012-09-21T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/IPhone_5.png/300px-IPhone_5.png\'/> <a title=\'Photo by Zach Vega (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:IPhone_5.png\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    },\n    {\n      \"key\": \"9\",\n      \"name\": \"HTC One\",\n      \"values\": {\n        \"weight\": 143,\n        \"price\": 189,\n        \"RAM\": 2048,\n        \"battery\": 2300,\n        \"camera\": 4,\n        \"memory_size\": 32,\n        \"screen_size\": 4.7,\n        \"brand\": \"HTC\",\n        \"rDate\": \"2013-03-01T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/7/70/HTC_One.png/149px-HTC_One.png\'/> <a title=\'Photo by M0rphzone (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:HTC_One.png\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    },\n    {\n      \"key\": \"10\",\n      \"name\": \"LG Optimus G\",\n      \"values\": {\n        \"weight\": 145,\n        \"price\": 189,\n        \"RAM\": 1024,\n        \"battery\": 2100,\n        \"camera\": 13,\n        \"memory_size\": 32,\n        \"screen_size\": 4.7,\n        \"brand\": \"LG\",\n        \"rDate\": \"2012-09-19T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/LG_Optimus_G_%28Black%29.jpg/330px-LG_Optimus_G_%28Black%29.jpg\'/> <a title=\'[CC BY 2.0 (http://creativecommons.org/licenses/by/2.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:LG_Optimus_G_(Black).jpg\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    },\n    {\n      \"key\": \"11\",\n      \"name\": \"Nokia Lumia 520\",\n      \"values\": {\n        \"weight\": 124,\n        \"price\": 199,\n        \"RAM\": 512,\n        \"battery\": 1430,\n        \"camera\": 5,\n        \"memory_size\": 8,\n        \"screen_size\": 4,\n        \"brand\": \"Nokia\",\n        \"rDate\": \"2013-02-25T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Lumia_520.jpg/450px-Lumia_520.jpg\'/> <a title=\'Photo by Krby Dambrns from Latvia (MWC Barcelona 2013 260  Uploaded by RaviC) [CC BY 2.0 (http://creativecommons.org/licenses/by/2.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:Lumia_520.jpg\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    },\n    {\n      \"key\": \"13\",\n      \"name\": \"Samsung Galaxy Ace 2 Black\",\n      \"values\": {\n        \"weight\": 122,\n        \"price\": 220,\n        \"RAM\": 768,\n        \"battery\": 1000,\n        \"camera\": 5,\n        \"memory_size\": 4,\n        \"screen_size\": 3.8,\n        \"brand\": \"Samsung\",\n        \"rDate\": \"2012-02-05T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Front_Ace_2.JPG/330px-Front_Ace_2.JPG\'/> <a title=\'Photo by Fan samsung ace2 (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:Front_Ace_2.JPG\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    },\n    {\n      \"key\": \"14\",\n      \"name\": \"Samsung Galaxy Mini 2 Black\",\n      \"values\": {\n        \"weight\": 105,\n        \"price\": 220,\n        \"RAM\": 512,\n        \"battery\": 1300,\n        \"camera\": 3.15,\n        \"memory_size\": 4,\n        \"screen_size\": 3.27,\n        \"brand\": \"Samsung\",\n        \"rDate\": \"2012-02-05T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/GT-S6500L.jpg/375px-GT-S6500L.jpg\'/> <a title=\'Photo by Eriqvaldezz (Own work) [GFDL (http://www.gnu.org/copyleft/fdl.html) or CC BY 3.0 (http://creativecommons.org/licenses/by/3.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:GT-S6500L.jpg\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    },\n    {\n      \"key\": \"15\",\n      \"name\": \"Sony Xperia P Silver\",\n      \"values\": {\n        \"weight\": 120,\n        \"price\": 255,\n        \"RAM\": 1024,\n        \"battery\": 1305,\n        \"camera\": 8,\n        \"memory_size\": 16,\n        \"screen_size\": 4,\n        \"brand\": \"Sony\",\n        \"rDate\": \"2012-02-27T00:00:00Z\"\n      },\n      \"description_html\": \"<img style=\'max-height: 100px; max-width: 100px;\'  src=\'http://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Xperia_P.jpg/330px-Xperia_P.jpg\'/> <a title=\'Photo by vsy (http://www.flickr.com/photos/vsy/7176314726/) [CC BY-SA 2.0 (http://creativecommons.org/licenses/by-sa/2.0)], via Wikimedia Commons\' href=\'http://commons.wikimedia.org/wiki/File:Xperia_P.jpg\' target=\'_blank\'> <img style=\'max-height: 14px; max-width: 14px;\'  src=\'http://mirrors.creativecommons.org/presskit/icons/cc.png\'/> </a>\"\n    }\n  ]\n}")]]>
</content>
                            </script>
                            <pluginContent>
                                <text>
                                    <![CDATA[{
  "subject": "phone",
  "columns": [
    {
      "key": "price",
      "type": "numeric",
      "goal": "min",
      "full_name": "Price",
      "is_objective": true,
      "format": "€####0.00"
    },
    {
      "key": "brand",
      "type": "categorical",
      "goal": "min",
      "full_name": "Brand",
      "is_objective": true,
      "range": [
        "Samsung",
        "Apple",
        "HTC",
        "LG",
        "Nokia",
        "Sony"
      ],
      "preference": [
        "Samsung",
        "Apple",
        "HTC",
        "LG",
        "Nokia",
        "Sony"
      ]
    },
    {
      "key": "RAM",
      "type": "text",
      "goal": "max",
      "full_name": "RAM (MB)",
      "is_objective": false
    },
    {
      "key": "screen_size",
      "type": "numeric",
      "goal": "max",
      "full_name": "Screen (inch)",
      "is_objective": true
    },
    {
      "key": "camera",
      "type": "numeric",
      "goal": "max",
      "full_name": "Camera",
      "is_objective": false,
      "format": "####0 MP"
    },
    {
      "key": "memory_size",
      "type": "numeric",
      "goal": "max",
      "full_name": "Memory",
      "is_objective": false,
      "format": "####0 GB"
    },
    {
      "key": "battery",
      "type": "numeric",
      "goal": "max",
      "full_name": "Battery (mAh)",
      "is_objective": false
    },
    {
      "key": "weight",
      "type": "numeric",
      "goal": "min",
      "full_name": "Weight",
      "is_objective": true,
      "format": "####0 g"
    },
    {
      "key": "rDate",
      "type": "datetime",
      "goal": "max",
      "full_name": "Release Date",
      "is_objective": false
    }
  ],
  "options": [
    {
      "key": " 1",
      "name": "Samsung Galaxy S4 White",
      "values": {
        "weight": 130,
        "price": 239,
        "RAM": 2048,
        "battery": 2600,
        "camera": 13,
        "memory_size": 16,
        "screen_size": 5,
        "brand": "Samsung",
        "rDate": "2013-04-29T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/Samsung_GALAXY_S4_zoom_%28White%29.jpg/800px-Samsung_GALAXY_S4_zoom_%28White%29.jpg'/> <a title='Photo by Samsung Belgium (Flickr: GALAXY S4 zoom (1)) [CC BY 2.0 (http://creativecommons.org/licenses/by/2.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:Samsung_GALAXY_S4_zoom_(White).jpg' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    },
    {
      "key": "2",
      "name": "Samsung Galaxy S4 Black",
      "values": {
        "weight": 130,
        "price": 239,
        "RAM": 2048,
        "battery": 2600,
        "camera": 13,
        "memory_size": 16,
        "screen_size": 5,
        "brand": "Samsung",
        "rDate": "2013-04-29T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/f/f2/Samsung_Galaxy_S4.jpg/200px-Samsung_Galaxy_S4.jpg'/><a title='Photo by Karlis Dambrans (Flickr: Samsung Galaxy S4) [CC BY 2.0 (http://creativecommons.org/licenses/by/2.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:Samsung_Galaxy_S4.jpg' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    },
    {
      "key": "3",
      "name": "Samsung Galaxy S3 White",
      "values": {
        "weight": 133,
        "price": 79,
        "RAM": 2048,
        "battery": 2100,
        "camera": 8,
        "memory_size": 16,
        "screen_size": 4.8,
        "brand": "Samsung",
        "rDate": "2012-05-29T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/d/d6/Samsung_Galaxy_S_III.png/300px-Samsung_Galaxy_S_III.png'/> <a title='Photo by GalaxyOptimus (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:Samsung_Galaxy_S_III.png' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    },
    {
      "key": "4",
      "name": "Samsung Galaxy S3 Blue",
      "values": {
        "weight": 133,
        "price": 79,
        "RAM": 2048,
        "battery": 2100,
        "camera": 8,
        "memory_size": 16,
        "screen_size": 4.8,
        "brand": "Samsung",
        "rDate": "2012-05-29T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/7/7a/Samsung_Galaxy_S_Advance_i9070.JPG/250px-Samsung_Galaxy_S_Advance_i9070.JPG'/> <a title='Photo by Macs79 (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:Samsung_Galaxy_S_Advance_i9070.JPG' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    },
    {
      "key": "5",
      "name": "Samsung Galaxy S3 mini White",
      "values": {
        "weight": 111,
        "price": 299,
        "RAM": 1024,
        "battery": 1000,
        "camera": 5,
        "memory_size": 8,
        "screen_size": 4,
        "brand": "Samsung",
        "rDate": "2012-10-01T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/6/6a/Samsung_Galaxy_S_III_mini.png/300px-Samsung_Galaxy_S_III_mini.png'/> <a title='Photo by GalaxyOptimus (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:Samsung_Galaxy_S_III_mini.png' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    },
    {
      "key": "6",
      "name": "Apple iPhone 5 White",
      "values": {
        "weight": 112,
        "price": 449,
        "RAM": 1024,
        "battery": 1440,
        "camera": 8,
        "memory_size": 32,
        "screen_size": 4,
        "brand": "Apple",
        "rDate": "2012-09-21T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/9/9d/IPhone5white.png/228px-IPhone5white.png'/> <a title='Photo by Pixeden.com [CC BY 3.0 (http://creativecommons.org/licenses/by/3.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:IPhone5white.png' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    },
    {
      "key": "7",
      "name": "Apple iPhone 5 Black",
      "values": {
        "weight": 112,
        "price": 449,
        "RAM": 1024,
        "battery": 1440,
        "camera": 8,
        "memory_size": 32,
        "screen_size": 4,
        "brand": "Apple",
        "rDate": "2012-09-21T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/f/fa/IPhone_5.png/300px-IPhone_5.png'/> <a title='Photo by Zach Vega (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:IPhone_5.png' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    },
    {
      "key": "9",
      "name": "HTC One",
      "values": {
        "weight": 143,
        "price": 189,
        "RAM": 2048,
        "battery": 2300,
        "camera": 4,
        "memory_size": 32,
        "screen_size": 4.7,
        "brand": "HTC",
        "rDate": "2013-03-01T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/7/70/HTC_One.png/149px-HTC_One.png'/> <a title='Photo by M0rphzone (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:HTC_One.png' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    },
    {
      "key": "10",
      "name": "LG Optimus G",
      "values": {
        "weight": 145,
        "price": 189,
        "RAM": 1024,
        "battery": 2100,
        "camera": 13,
        "memory_size": 32,
        "screen_size": 4.7,
        "brand": "LG",
        "rDate": "2012-09-19T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/e/e1/LG_Optimus_G_%28Black%29.jpg/330px-LG_Optimus_G_%28Black%29.jpg'/> <a title='[CC BY 2.0 (http://creativecommons.org/licenses/by/2.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:LG_Optimus_G_(Black).jpg' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    },
    {
      "key": "11",
      "name": "Nokia Lumia 520",
      "values": {
        "weight": 124,
        "price": 199,
        "RAM": 512,
        "battery": 1430,
        "camera": 5,
        "memory_size": 8,
        "screen_size": 4,
        "brand": "Nokia",
        "rDate": "2013-02-25T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Lumia_520.jpg/450px-Lumia_520.jpg'/> <a title='Photo by Krby Dambrns from Latvia (MWC Barcelona 2013 260  Uploaded by RaviC) [CC BY 2.0 (http://creativecommons.org/licenses/by/2.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:Lumia_520.jpg' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    },
    {
      "key": "13",
      "name": "Samsung Galaxy Ace 2 Black",
      "values": {
        "weight": 122,
        "price": 220,
        "RAM": 768,
        "battery": 1000,
        "camera": 5,
        "memory_size": 4,
        "screen_size": 3.8,
        "brand": "Samsung",
        "rDate": "2012-02-05T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/3/3a/Front_Ace_2.JPG/330px-Front_Ace_2.JPG'/> <a title='Photo by Fan samsung ace2 (Own work) [CC BY-SA 3.0 (http://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:Front_Ace_2.JPG' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    },
    {
      "key": "14",
      "name": "Samsung Galaxy Mini 2 Black",
      "values": {
        "weight": 105,
        "price": 220,
        "RAM": 512,
        "battery": 1300,
        "camera": 3.15,
        "memory_size": 4,
        "screen_size": 3.27,
        "brand": "Samsung",
        "rDate": "2012-02-05T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/3/3d/GT-S6500L.jpg/375px-GT-S6500L.jpg'/> <a title='Photo by Eriqvaldezz (Own work) [GFDL (http://www.gnu.org/copyleft/fdl.html) or CC BY 3.0 (http://creativecommons.org/licenses/by/3.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:GT-S6500L.jpg' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    },
    {
      "key": "15",
      "name": "Sony Xperia P Silver",
      "values": {
        "weight": 120,
        "price": 255,
        "RAM": 1024,
        "battery": 1305,
        "camera": 8,
        "memory_size": 16,
        "screen_size": 4,
        "brand": "Sony",
        "rDate": "2012-02-27T00:00:00Z"
      },
      "description_html": "<img style='max-height: 100px; max-width: 100px;'  src='http://upload.wikimedia.org/wikipedia/commons/thumb/a/ac/Xperia_P.jpg/330px-Xperia_P.jpg'/> <a title='Photo by vsy (http://www.flickr.com/photos/vsy/7176314726/) [CC BY-SA 2.0 (http://creativecommons.org/licenses/by-sa/2.0)], via Wikimedia Commons' href='http://commons.wikimedia.org/wiki/File:Xperia_P.jpg' target='_blank'> <img style='max-height: 14px; max-width: 14px;'  src='http://mirrors.creativecommons.org/presskit/icons/cc.png'/> </a>"
    }
  ]
}]]>
</text>
                            </pluginContent>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the text on the output." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The text you entered." id="3" />
                        </Box>
                        <Box name="Top 5 Traits" id="20" localization="8" tooltip="This box uses Personality Insights, the Bluemix service designed to identify the personality of a person by analyzing a block of text written/spoken by the person. Personality Insights requires a minimum of 100 words, but suggests upwords of 2000 words.&#x0A;&#x0A;A parser is included that skims through the data to find particualy strong or weak traits.&#x0A;&#x0A;Input: The block of English text used to analyze a personality. Minimun 100 words, but 2000+ words suggested.&#x0A;&#x0A;Output: A sentence that identifies particularly strong or weak traits of the personality." x="350" y="903">
                            <bitmap>media/images/box/watson-lib-icons/diagram_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.watson = ALProxy('ALWatson')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        pi = self.watson.personality(p,None,None)
        #Must parse pi to obtain the desired traits
        #self.logger.info(json.dumps(pi, sort_keys=True, indent=4, separators=(',', ': ')))
        traits = self.extract_traits(json.loads(pi))
        sentence = self.create_sentence(traits)
        self.onStopped(sentence) #activate the output of the box
        pass

    #Analyze a json generated from Watson PI service, and return an array of good and bad traits
    def extract_traits(self, jsn):
        #finds the big 5, their percentages, and then the highest and lowest in each
        #iterates thru the 'Big 5' and get the percentage for each
        good = []
        bad = []
        for x in range(0,5):
            name = jsn['tree']['children'][0]['children'][0]['children'][x]['name']
            percent = jsn['tree']['children'][0]['children'][0]['children'][x]['percentage']

            #set both to the first, then compare all, looking for the extremes (if there are ties, just use the first one)
            sub_high_percent = jsn['tree']['children'][0]['children'][0]['children'][x]['children'][0]['percentage']
            sub_high_name = jsn['tree']['children'][0]['children'][0]['children'][x]['children'][0]['name']
            sub_low_percent = jsn['tree']['children'][0]['children'][0]['children'][x]['children'][0]['percentage']
            sub_low_name = jsn['tree']['children'][0]['children'][0]['children'][x]['children'][0]['name']

            for y in range(1,6): #check the rest of the 5 sub categories in each big 5
                if sub_high_percent < jsn['tree']['children'][0]['children'][0]['children'][x]['children'][y]['percentage']:
                    sub_high_percent = jsn['tree']['children'][0]['children'][0]['children'][x]['children'][y]['percentage']
                    sub_high_name = jsn['tree']['children'][0]['children'][0]['children'][x]['children'][y]['name']
                if sub_low_percent > jsn['tree']['children'][0]['children'][0]['children'][x]['children'][y]['percentage']:
                    sub_low_percent = jsn['tree']['children'][0]['children'][0]['children'][x]['children'][y]['percentage']
                    sub_low_name = jsn['tree']['children'][0]['children'][0]['children'][x]['children'][y]['name']
            #Have the extremes, lets only keep the highest if the big 5 category is >50%, or lowest otherwise
            if percent > .5:
                good.append(sub_high_name)
            else:
                bad.append(sub_low_name)

        #Can do whatever with the data, but I'm going to only send back the best and worst traits
        return [good, bad]


    #Makes an observation based on the analyzed traits
    def create_sentence(self, evaluation):
        sent = ""
        good_traits = len(evaluation[0])
        bad_traits = len(evaluation[1])

        #create a sentence using the traits given
        if good_traits == 1:
            sent = sent + "Your " + evaluation[0][0].encode('utf-8') + " seems to be your strongest trait."
        elif good_traits > 1:
            sent = sent + "Your stongest traits seem to be your "
            for good in range(0, good_traits - 1):
                sent = sent + evaluation[0][good].encode('utf-8') + ", "
            sent = sent + " and your " + evaluation[0][good_traits - 1].encode('utf-8') + ". "

        if bad_traits == 1:
            sent = sent + "You could improve on your " + evaluation[1][0].encode('utf-8') + " though."
        elif bad_traits > 1:
            sent = sent + "You could improve on your "
            for bad in range(0, bad_traits - 1):
                sent = sent + evaluation[1][bad].encode('utf-8') + ", "
            sent = sent + " and your " + evaluation[1][bad_traits - 1].encode('utf-8') + "."

        return sent]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Input the block of English text used to analyze a personality. Need at least 100 words, but for best results, Bluemix suggests at least 2000." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="A single sentence is produced by the box, which identifies the strongest and weakest traits shown by the input personality." id="3" />
                        </Box>
                        <Box name="Watson Listening" id="25" localization="8" tooltip="This box makes the robot listen for human speech in English, and transcribes it. This is done by using the Bluemix Speech to Text (STT) service.&#x0A;&#x0A;Input: A signal to tell the box when to start listening.&#x0A;&#x0A;Output: A string of text, which is a transcription of what the robot heard." x="76" y="7">
                            <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="Record Sound_onStart" type="1" type_size="1" nature="2" inner="0" tooltip="This input has been automatically generated&#x0A;by converting several boxes into a single box." id="2" />
                            <Output name="WatsonListening_onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="This output has been automatically generated&#x0A;by converting several boxes into a single box." id="3" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Watson Listening" id="5" localization="8" tooltip="This box makes the robot listen for human speech in English, and transcribes it. This is done by using the Bluemix Speech to Text (STT) service.&#x0A;&#x0A;Input: A signal to tell the box when to start listening.&#x0A;&#x0A;Output: A string of text, which is a transcription of what the robot heard." x="364" y="4">
                                                <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        self.watson = ALProxy('ALWatson')

    def onUnload(self):
        pass

    def onInput_onStart(self):
        speech = self.watson.stt()
        trans = json.loads(speech)
        self.onStopped(trans['results'][0]['alternatives'][0]['transcript'].encode('utf-8'))]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="A signal to notify the box when it needs to start listening." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="A string of text that is the transcription of what the robot heard." id="3" />
                                            </Box>
                                            <Box name="Record Sound" id="24" localization="8" tooltip='Record a sound on the robot. You can choose to record only with one&#x0A;microphone (the front head microphone) in ogg format, or with four microphones&#x0A;(front, sides and rear head microphones) in wav format.&#x0A;&#x0A;If &quot;Temporary storage&quot; isn&apos;t checked, the output sound file is located in &quot;~/recordings/microphones/&lt;File name&gt;&quot;.&#x0A;Else, it is located in a temporary directory&#x0A;&#x0A;The onStopped output is stimulated at the end of the recording and contains the absolute path to the output sound file&#x0A;&#x0A;V1.1.0&#x0A;' x="143" y="0">
                                                <bitmap>media/images/box/interaction/rec_sound.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Launches the recording of the sound." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stops the recording of the sound." id="3" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Returns the absolute path of the output sound file at the end of the recording" id="4" />
                                                <Parameter name="File name" inherits_from_parent="0" content_type="3" value="recording" default_value="recording" custom_choice="0" tooltip="Name of the destination file without its extension." id="5" />
                                                <Parameter name="Microphones used" inherits_from_parent="0" content_type="3" value="Front, sides and rear head microphones (.wav)" default_value="Front, sides and rear head microphones (.wav)" custom_choice="0" tooltip="Microphones used to record the sound.&#x0A;&#x0A;Note: If you use only the front head microphone the file will be saved in ogg format. If you use the&#x0A;front, sides and rear head microphones it will be saved in wav format." id="6">
                                                    <Choice value="Front head microphone only (.ogg)" />
                                                    <Choice value="Front, sides and rear head microphones (.wav)" />
                                                </Parameter>
                                                <Parameter name="Temporary storage" inherits_from_parent="0" content_type="0" value="0" default_value="1" tooltip="Choose if the file should be stored as a temporary file so it is removed as soon&#x0A;as the behavior is unloaded.&#x0A;&#x0A;When this option is disabled the file is stored in ~/recordings/microphones. You can&#x0A;then get it on your computer using the menu Connection/File transfer.&#x0A;&#x0A;When this option is enabled the file is stored in the temporary folder of the behavior." id="7" />
                                                <Parameter name="Timeout (s)" inherits_from_parent="0" content_type="2" value="3" default_value="5" min="0.1" max="60" tooltip="Duration of the recording in seconds." id="8" />
                                                <Timeline enable="0">
                                                    <BehaviorLayer name="behavior_layer1">
                                                        <BehaviorKeyframe name="keyframe1" index="1">
                                                            <Diagram scale="100">
                                                                <Box name="Rec. Sound File" id="4" localization="8" tooltip="Record a sound on the robot. You can choose to record only with one&#x0A;microphone (the front head microphone) in ogg format, or with four microphones&#x0A;(front, sides and rear head&#x0A;microphones) in wav format." x="562" y="100">
                                                                    <bitmap>media/images/box/interaction/rec_sound.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        try:
            self.ad = ALProxy("ALAudioDevice")
        except Exception as e:
            self.ad = None
            self.logger.error(e)
        self.filepath = ""

    def onLoad(self):
        self.bIsRecording = False
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False
        if( self.bIsRecording ):
            self.ad.stopMicrophonesRecording()
            self.bIsRecording = False

    def onInput_onStart(self, p):
        if(self.bIsRunning):
            return
        self.bIsRunning = True
        sExtension = self.toExtension( self.getParameter("Microphones used") )
        self.filepath = p + sExtension
        if self.ad:
            self.ad.startMicrophonesRecording( self.filepath )
            self.bIsRecording = True
        else:
            self.logger.warning("No sound recorded")

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped(self.filepath)

    def toExtension(self, sMicrophones):
        if( sMicrophones == "Front head microphone only (.ogg)" ):
            return ".ogg"
        else:
            return ".wav"]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Launches the recording of the sound. The data received on this input must be the&#x0A;filename of the sound." id="2" />
                                                                    <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stops the recording of the sound." id="3" />
                                                                    <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="Returns the absolute path of the output sound file at the end of the recording" id="4" />
                                                                    <Parameter name="Microphones used" inherits_from_parent="1" content_type="3" value="Front, sides and rear head microphones (.wav)" default_value="Front, sides and rear head microphones (.wav)" custom_choice="0" tooltip="Microphones used to record the sound.&#x0A;&#x0A;Note: If you use only the front head microphone the file will be saved in ogg format. If you use the&#x0A;front, sides and rear head microphones it will be saved in wav format." id="5">
                                                                        <Choice value="Front head microphone only (.ogg)" />
                                                                        <Choice value="Front, sides and rear head microphones (.wav)" />
                                                                    </Parameter>
                                                                </Box>
                                                                <Box name="Wait" id="13" localization="8" tooltip="Wait a moment before sending a bang on the output. The wait can be stopped any&#x0A;time. You may restart it any time, and it will start over." x="420" y="161">
                                                                    <bitmap>media/images/box/wait.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[import threading # opkg install python-threading
class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.tb = False

    def onUnload(self):
        if( self.tb ):
            self.tb.cancel()
            self.tb = False

    def triggerOutput( self, rPeriod = 1 ):
        self.onUnload() # to clean everything
        self.timerOutput()

    def startTimer( self, rPeriod = 1 ):
        if( self.tb ):
            self.tb.cancel()
        self.tb = threading.Timer( rPeriod, self.triggerOutput, [rPeriod] )
        self.tb.start()

    def onInput_onStart(self):
        self.startTimer( self.getParameter("Timeout (s)") )

    def onInput_onStop(self):
        bRunning = self.tb
        self.onUnload()
        if( bRunning ):
            self.timerOutput()]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Start the Wait box with the configured timeout value." id="2" />
                                                                    <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stop the wait and stimulate the output." id="3" />
                                                                    <Output name="timerOutput" type="1" type_size="1" nature="1" inner="0" tooltip="Send a bang once time set in parameters is ellapsed, or if the box is stopped." id="4" />
                                                                    <Parameter name="Timeout (s)" inherits_from_parent="1" content_type="2" value="5" default_value="1" min="0" max="5000" tooltip="Duration the box waits before stimulating the output." id="5" />
                                                                </Box>
                                                                <Box name="Get File Name" id="10" localization="8" tooltip="Use this box to choose an attached file in its parameters. The filename will be sent on&#x0A;the output when the input is stimulated." x="234" y="95">
                                                                    <bitmap>media/images/box/folder.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[import os
class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.framemanager = ALProxy("ALFrameManager")

    def onInput_onStart(self):
        if( self.getParameter("Temporary storage") ):
            import tempfile
            path = tempfile.mkdtemp() + "/"
        else:
            path = os.path.expanduser('~') + "/recordings/microphones/"
        self.onStopped( path + self.getParameter("File name") )]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the filepath on the output." id="2" />
                                                                    <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The filepath of the selected resource file." id="3" />
                                                                    <Parameter name="File name" inherits_from_parent="1" content_type="3" value="recording" default_value="" custom_choice="0" tooltip="Name of the file." id="4" />
                                                                    <Parameter name="Temporary storage" inherits_from_parent="1" content_type="0" value="1" default_value="1" tooltip="Choose if the file should be stored as a temporary file so it is removed as soon&#x0A;as the behavior is unloaded.&#x0A;&#x0A;When this option is enabled the file is stored in ~/.cache/currentChoregrapheBehavior&#x0A;or in ~/.cache/&lt;project_name&gt; when you play the behavior from the&#x0A;behavior manager.&#x0A;&#x0A;When it is disabled the file is stored in ~/recordedSounds. You can&#x0A;then get it on your computer using the menu Connection/File transfer." id="5" />
                                                                </Box>
                                                                <Box name="Listening LEDS" id="2" localization="8" tooltip="" x="416" y="268">
                                                                    <bitmap>media/images/box/box-python-script.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        self.leds = ALProxy("ALLeds")

    def onUnload(self):
        pass

    def onInput_onStart(self):
        #want RGB to be (31,88,255) -> 0x1F58FF
        self.leds.rotateEyes(2054399, 0.80, self.getParameter('Timeout (s)'))]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                                    <Parameter name="Timeout (s)" inherits_from_parent="1" content_type="2" value="3" default_value="5" min="0.1" max="60" tooltip="Duration of the recording in seconds." id="3" />
                                                                </Box>
                                                                <Box name="Reset Eyes" id="1" localization="8" tooltip="" x="570" y="230">
                                                                    <bitmap>media/images/box/box-python-script.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        self.leds = ALProxy("ALLeds")

    def onUnload(self):
        pass

    def onInput_onStart(self):
        self.leds.reset('FaceLeds')]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                                </Box>
                                                                <Link inputowner="0" indexofinput="4" outputowner="4" indexofoutput="4" />
                                                                <Link inputowner="4" indexofinput="3" outputowner="13" indexofoutput="4" />
                                                                <Link inputowner="10" indexofinput="2" outputowner="0" indexofoutput="2" />
                                                                <Link inputowner="13" indexofinput="2" outputowner="10" indexofoutput="3" />
                                                                <Link inputowner="4" indexofinput="2" outputowner="10" indexofoutput="3" />
                                                                <Link inputowner="2" indexofinput="2" outputowner="10" indexofoutput="3" />
                                                                <Link inputowner="1" indexofinput="2" outputowner="13" indexofoutput="4" />
                                                            </Diagram>
                                                        </BehaviorKeyframe>
                                                    </BehaviorLayer>
                                                </Timeline>
                                                <Resource name="Audio recorder" type="Lock" timeout="0" />
                                            </Box>
                                            <Link inputowner="5" indexofinput="2" outputowner="24" indexofoutput="4" />
                                            <Link inputowner="24" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="0" indexofinput="3" outputowner="5" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                        </Box>
                        <Box name="Text Edit (8)" id="5" localization="8" tooltip="Send the text you entered when the input is stimulated." plugin="textedit_plugin" x="65" y="195">
                            <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("hello how are you")]]>
</content>
                            </script>
                            <pluginContent>
                                <text>
                                    <![CDATA[hello how are you]]>
</text>
                            </pluginContent>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the text on the output." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The text you entered." id="3" />
                        </Box>
                        <Box name="Set Language" id="24" localization="8" tooltip="Select the language you would like the robot to speak and understand. Any following call to&#x0A;ALSpeechRecognition (Speech Reco. box for instance) or ALTextToSpeech (Say box&#x0A;for instance) will use this language." x="746" y="217">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        try:
            self.tts = ALProxy("ALTextToSpeech")
        except:
            self.logger.warn("ALTextToSpeech is not available, language setting cannot be applied to speech")
            self.tts = None

        try:
            self.asr = ALProxy("ALSpeechRecognition")
        except:
            self.logger.warn("ALSpeechRecognition is not available, language setting cannot be applied to recognition")
            self.asr = None

        try:
            self.dialog = ALProxy("ALDialog")
        except:
            self.logger.warn("ALDialog is not available, language setting cannot be applied to dialog")
            self.dialog = None

    def onInput_onSet(self):
        lang = self.getParameter("Language")
        try:
            if self.asr:
                self.asr.setLanguage( self.getParameter("Language") )
            if self.tts:
                self.tts.setLanguage( self.getParameter("Language") )
            if self.dialog:
                self.dialog.setLanguage( self.getParameter("Language") )
            if self.tts is None and self.asr is None and self.dialog is None:
                raise RuntimeError("Cannot set language: neither ALTextToSpeech nor ALSpeechRecognition nor ALDialog is available.")
            self.onReady()
        except:
            error = "Language " + lang + " cannot be set."
            self.logger.warn(error)
            self.onError(error)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onSet" type="1" type_size="1" nature="1" inner="0" tooltip="The data is set when a signal is received on this input." id="2" />
                            <Output name="onReady" type="1" type_size="1" nature="2" inner="0" tooltip="Signal sent when the data has been set." id="3" />
                            <Output name="onError" type="3" type_size="1" nature="2" inner="0" tooltip="Error output:&#x0A;- triggered if the language asked cannot be set" id="4" />
                            <Parameter name="Language" inherits_from_parent="0" content_type="3" value="English" default_value="English" custom_choice="1" tooltip="Set the language the robot speaks and understands." id="5">
                                <Choice value="Arabic" />
                                <Choice value="Brazilian" />
                                <Choice value="Chinese" />
                                <Choice value="Czech" />
                                <Choice value="Danish" />
                                <Choice value="Dutch" />
                                <Choice value="English" />
                                <Choice value="Finnish" />
                                <Choice value="French" />
                                <Choice value="German" />
                                <Choice value="Italian" />
                                <Choice value="Japanese" />
                                <Choice value="Korean" />
                                <Choice value="Polish" />
                                <Choice value="Portuguese" />
                                <Choice value="Russian" />
                                <Choice value="Spanish" />
                                <Choice value="Swedish" />
                                <Choice value="Turkish" />
                            </Parameter>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Watson Open Dialouge" id="27" localization="8" tooltip="This box makes the robot say whatever text is given to it, in the voice of Watson. This is done by using the Bluemix Text to Speech (TTS) service.&#x0A;&#x0A;Input: The string of text that you want Watson to say.&#x0A;&#x0A;Output: There is no box output, but this causes the robot to speak." x="68" y="1426">
                            <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import os
import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        if not os.path.exists('/home/nao/recordings/watson_tts/'):
            os.makedirs('/home/nao/recordings/watson_tts/')
        self.memory = ALProxy("ALMemory")


    def onLoad(self):
        #put initialization code here
        self.watson = ALProxy('ALWatson')

        pass

    def onUnload(self):
        #put clean-up code here
        self.memory = None
        pass

    def onInput_onStart(self):
        self.logger.info(self.getParameter("dialog_id"))
        self.logger.info(type(self.watson))

        s = self.watson.dialog_initiate(self.getParameter("dialog_id"), None, None)
        self.logger.info( s )
        #self.logger.info( type(s) )
        json_str = json.loads(s)
        self.memory.insertData('dialog/dialog_id', self.getParameter("dialog_id") )
        self.memory.insertData('dialog/client_id', json_str["client_id"] )
        self.memory.insertData('dialog/conversation_id', json_str["conversation_id"] )
        #self.introduction(str(json_str['response'][0]))
        self.onStopped() #activate the output of the box]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="" id="2" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="A signal sent when box behavior is finished, and the robot speaks the given text." id="3" />
                            <Output name="introduction" type="3" type_size="1" nature="1" inner="0" tooltip="" id="4" />
                            <Parameter name="dialog_id" inherits_from_parent="0" content_type="3" value="d252fb0d-6143-4852-92a8-3729859627a5" default_value="" custom_choice="0" tooltip="" id="5" />
                        </Box>
                        <Box name="Text Edit (10)" id="31" localization="8" tooltip="Send the text you entered when the input is stimulated." plugin="textedit_plugin" x="189" y="1428">
                            <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("How are you?")]]>
</content>
                            </script>
                            <pluginContent>
                                <text>
                                    <![CDATA[How are you?]]>
</text>
                            </pluginContent>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the text on the output." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The text you entered." id="3" />
                        </Box>
                        <Box name="Watson Continue Dialouge" id="32" localization="8" tooltip="This box makes the robot say whatever text is given to it, in the voice of Watson. This is done by using the Bluemix Text to Speech (TTS) service.&#x0A;&#x0A;Input: The string of text that you want Watson to say.&#x0A;&#x0A;Output: There is no box output, but this causes the robot to speak." x="453" y="1427">
                            <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import os
import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        if not os.path.exists('/home/nao/recordings/watson_tts/'):
            os.makedirs('/home/nao/recordings/watson_tts/')
        self.watson = ALProxy('ALWatson')
        self.memory = ALProxy("ALMemory")


    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        self.memory = None
        pass

    def onInput_question(self, question):
        client_id = self.memory.getData("dialog/client_id")
        conversation_id = self.memory.getData("dialog/conversation_id")
        dialog_id = self.memory.getData("dialog/dialog_id")
        s = self.watson.dialog_converse(dialog_id, client_id, conversation_id, question, None, None)
        json_str = json.loads( s )
        self.onStopped(str(json_str['response'][0]))]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="question" type="3" type_size="1" nature="2" inner="0" tooltip="" id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="A signal sent when box behavior is finished, and the robot speaks the given text." id="3" />
                            <Parameter name="dialog_id" inherits_from_parent="0" content_type="3" value="d252fb0d-6143-4852-92a8-3729859627a5" default_value="" custom_choice="0" tooltip="" id="4" />
                        </Box>
                        <Box name="Say Text (4)" id="33" localization="8" tooltip="Say the text received on its input." x="576" y="1423">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Watson Listening Fast (1)" id="29" localization="8" tooltip="This box makes the robot listen for human speech in English, and transcribes it. This is done by using the Bluemix Speech to Text (STT) service.&#x0A;&#x0A;Input: A signal to tell the box when to start listening.&#x0A;&#x0A;Output: A string of text, which is a transcription of what the robot heard." x="328" y="1545">
                            <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        self.watson = ALProxy('ALWatson')
        self.leds = ALProxy("ALLeds")


    def onUnload(self):
        pass

    def onInput_onStart(self):
        s = self.watson.stt_stream()
        self.logger.info("SttStreamResult: {}".format(s))
        self.logger.warning("SttStreamResult: {}".format(s))

        s_json = json.loads(s)
        try:
            result = s_json['results'][0]['alternatives'][0]['transcript']
        except:
            self.logger.warning("ONERROR CALLED")
            self.onError()
        self.onStopped( str(result) )
        #id = self.leds.post.fadeRGB("FaceLeds",20991, .7)

        #try:
        #    self.onStopped( str(s_json['results'][0]['alternatives'][0]['transcript']) )
        #    #self.leds.wait(id, 0)
        #except:
        #    self.logger.info("STT onError called")
        #    self.onError()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="A signal to notify the box when it needs to start listening." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="A string of text that is the transcription of what the robot heard." id="3" />
                            <Output name="onError" type="1" type_size="1" nature="1" inner="0" tooltip="" id="4" />
                        </Box>
                        <Box name="Watson Open Dialouge (1)" id="30" localization="8" tooltip="This box makes the robot say whatever text is given to it, in the voice of Watson. This is done by using the Bluemix Text to Speech (TTS) service.&#x0A;&#x0A;Input: The string of text that you want Watson to say.&#x0A;&#x0A;Output: There is no box output, but this causes the robot to speak." x="65" y="1546">
                            <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import os
import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        if not os.path.exists('/home/nao/recordings/watson_tts/'):
            os.makedirs('/home/nao/recordings/watson_tts/')
        self.memory = ALProxy("ALMemory")


    def onLoad(self):
        #put initialization code here
        self.watson = ALProxy('ALWatson')

        pass

    def onUnload(self):
        #put clean-up code here
        self.memory = None
        pass

    def onInput_onStart(self):
        self.logger.info(self.getParameter("dialog_id"))
        self.logger.info(type(self.watson))

#        s = self.watson.dialog_initiate(self.getParameter("dialog_id"), None, None)
        s = self.watson.dialog_initiate(None, None)
        self.logger.info( s )
        #self.logger.info( type(s) )
        json_str = json.loads(s)
        self.memory.insertData('dialog/dialog_id', self.getParameter("dialog_id") )
        self.memory.insertData('dialog/client_id', json_str["client_id"] )
        self.memory.insertData('dialog/conversation_id', json_str["conversation_id"] )
        self.introduction(str(json_str['response'][0]))
        self.onStopped() #activate the output of the box]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="" id="2" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="A signal sent when box behavior is finished, and the robot speaks the given text." id="3" />
                            <Output name="introduction" type="3" type_size="1" nature="1" inner="0" tooltip="" id="4" />
                            <Parameter name="dialog_id" inherits_from_parent="0" content_type="3" value="d252fb0d-6143-4852-92a8-3729859627a5" default_value="" custom_choice="0" tooltip="" id="5" />
                        </Box>
                        <Box name="Watson Continue Dialouge (1)" id="35" localization="8" tooltip="This box makes the robot say whatever text is given to it, in the voice of Watson. This is done by using the Bluemix Text to Speech (TTS) service.&#x0A;&#x0A;Input: The string of text that you want Watson to say.&#x0A;&#x0A;Output: There is no box output, but this causes the robot to speak." x="469" y="1546">
                            <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import os
import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        if not os.path.exists('/home/nao/recordings/watson_tts/'):
            os.makedirs('/home/nao/recordings/watson_tts/')
        self.watson = ALProxy('ALWatson')
        self.memory = ALProxy("ALMemory")


    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        self.memory = None
        pass

    def onInput_question(self, question):
        client_id = self.memory.getData("dialog/client_id")
        conversation_id = self.memory.getData("dialog/conversation_id")
        dialog_id = self.memory.getData("dialog/dialog_id")
        s = self.watson.dialog_converse(dialog_id, client_id, conversation_id, question, None, None)
        json_str = json.loads( s )
        self.onStopped(str(json_str['response'][0]))]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="question" type="3" type_size="1" nature="2" inner="0" tooltip="" id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="A signal sent when box behavior is finished, and the robot speaks the given text." id="3" />
                            <Parameter name="dialog_id" inherits_from_parent="0" content_type="3" value="d252fb0d-6143-4852-92a8-3729859627a5" default_value="" custom_choice="0" tooltip="" id="4" />
                        </Box>
                        <Box name="Say Text (3)" id="36" localization="8" tooltip="Say the text received on its input." x="592" y="1542">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Say Text (5)" id="38" localization="8" tooltip="Say the text received on its input." x="191" y="1547">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Watson Open Dialouge (2)" id="37" localization="8" tooltip="This box makes the robot say whatever text is given to it, in the voice of Watson. This is done by using the Bluemix Text to Speech (TTS) service.&#x0A;&#x0A;Input: The string of text that you want Watson to say.&#x0A;&#x0A;Output: There is no box output, but this causes the robot to speak." x="57" y="1654">
                            <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import os
import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        if not os.path.exists('/home/nao/recordings/watson_tts/'):
            os.makedirs('/home/nao/recordings/watson_tts/')
        self.memory = ALProxy("ALMemory")


    def onLoad(self):
        #put initialization code here
        self.watson = ALProxy('ALWatson')

        pass

    def onUnload(self):
        #put clean-up code here
        self.memory = None
        pass

    def onInput_onStart(self):
        #self.logger.info(self.getParameter("dialog_id"))
        #self.logger.info(type(self.watson))

#        s = self.watson.dialog_initiate(self.getParameter("dialog_id"), None, None)
        s = self.watson.dialog_initiate( None, None)
        self.logger.info( s )
        #self.logger.info( type(s) )
        json_str = json.loads(s)
        #self.memory.insertData('dialog/dialog_id', self.getParameter("dialog_id") )
        self.memory.insertData('dialog/client_id', json_str["client_id"] )
        self.memory.insertData('dialog/conversation_id', json_str["conversation_id"] )
        self.onStopped(str(json_str['response'][0]))
        #self.onStopped() #activate the output of the box]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="" id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="A signal sent when box behavior is finished, and the robot speaks the given text." id="3" />
                        </Box>
                        <Box name="Watson Continue Dialouge (2)" id="40" localization="8" tooltip="This box makes the robot say whatever text is given to it, in the voice of Watson. This is done by using the Bluemix Text to Speech (TTS) service.&#x0A;&#x0A;Input: The string of text that you want Watson to say.&#x0A;&#x0A;Output: There is no box output, but this causes the robot to speak." x="446" y="1660">
                            <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import os
import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        if not os.path.exists('/home/nao/recordings/watson_tts/'):
            os.makedirs('/home/nao/recordings/watson_tts/')
        self.watson = ALProxy('ALWatson')
        self.memory = ALProxy("ALMemory")


    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        self.memory = None
        pass

    def onInput_question(self, question):
        client_id = self.memory.getData("dialog/client_id")
        conversation_id = self.memory.getData("dialog/conversation_id")

        ''' Debug Prints '''
        #self.logger.info( client_id )
        #self.logger.info( conversation_id )
        #self.logger.info( question )

        s = self.watson.dialog_converse(client_id, conversation_id, question, None, None)

        ''' Debug Prints '''
        #self.logger.info( s )
        #self.logger.info(type(s))

        json_str = json.loads( s )
        self.onStopped(str(json_str['response'][0]))]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="question" type="3" type_size="1" nature="2" inner="0" tooltip="" id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="A signal sent when box behavior is finished, and the robot speaks the given text." id="3" />
                            <Parameter name="dialog_id" inherits_from_parent="0" content_type="3" value="d252fb0d-6143-4852-92a8-3729859627a5" default_value="" custom_choice="0" tooltip="" id="4" />
                        </Box>
                        <Box name="Say Text (6)" id="41" localization="8" tooltip="Say the text received on its input." x="569" y="1655">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Say Text (7)" id="42" localization="8" tooltip="Say the text received on its input." x="189" y="1657">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Convo Text Init" id="34" localization="8" tooltip="This box makes the robot say whatever text is given to it, in the voice of Watson. This is done by using the Bluemix Text to Speech (TTS) service.&#x0A;&#x0A;Input: The string of text that you want Watson to say.&#x0A;&#x0A;Output: There is no box output, but this causes the robot to speak." x="56" y="1775">
                            <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import os
import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.memory = ALProxy("ALMemory")


    def onLoad(self):
        #put initialization code here
        self.watson = ALProxy('ALWatson')

        pass

    def onUnload(self):
        #put clean-up code here
        self.memory = None
        pass

    def onInput_onStart(self):
        s = self.watson.conversation_text_in_initiate( None, None)
        json_str = json.loads(s)

        # Data is comming back with an array of joined responses
        outputArray = json_str['greeting']
        outputString = ''
        for s1 in outputArray:
            #self.logger.info( str(s1) )
            outputString = str(outputString) + str(s1)

        # Store Client ID
        conversation_id = str(json_str['conversation_id'])
        self.logger.info( conversation_id )
        self.memory.insertData('conversation_text_in/conversation_id', conversation_id )

        # Output response
        self.introduction(str(outputString))
        self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="" id="2" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="A signal sent when box behavior is finished, and the robot speaks the given text." id="3" />
                            <Output name="introduction" type="3" type_size="1" nature="1" inner="0" tooltip="" id="4" />
                        </Box>
                        <Box name="Say Text (8)" id="43" localization="8" tooltip="Say the text received on its input." x="180" y="1776">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Convo Text Continue" id="44" localization="8" tooltip="This box makes the robot say whatever text is given to it, in the voice of Watson. This is done by using the Bluemix Text to Speech (TTS) service.&#x0A;&#x0A;Input: The string of text that you want Watson to say.&#x0A;&#x0A;Output: There is no box output, but this causes the robot to speak." x="432" y="1777">
                            <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import os
import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.memory = ALProxy("ALMemory")


    def onLoad(self):
        #put initialization code here
        self.watson = ALProxy('ALWatson')

        pass

    def onUnload(self):
        #put clean-up code here
        self.memory = None
        pass

    def onInput_onStart(self, p):
        conversation_id = self.memory.getData("conversation_text_in/conversation_id")
        body = {"referrer": {"id": "", "type": "ask"}, "options": {"max_items": 0, "properties": {}}}
        body['message'] = str(p)
        s = self.watson.conversation_text_in_converse( conversation_id, json.dumps(body) , None, None)
        #self.logger.info( str(s) )
        json_str = json.loads(s)

        # Output response
        self.introduction(str(json_str['responses'][0]['text'] ))
        self.onStopped()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="" id="2" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="A signal sent when box behavior is finished, and the robot speaks the given text." id="3" />
                            <Output name="introduction" type="3" type_size="1" nature="1" inner="0" tooltip="" id="4" />
                        </Box>
                        <Box name="Say Text (9)" id="46" localization="8" tooltip="Say the text received on its input." x="558" y="1773">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.tts = ALProxy('ALTextToSpeech')
        self.ttsStop = ALProxy('ALTextToSpeech', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.ttsStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            sentence = "\RSPD="+ str( self.getParameter("Speed (%)") ) + "\ "
            sentence += "\VCT="+ str( self.getParameter("Voice shaping (%)") ) + "\ "
            sentence += str(p)
            sentence +=  "\RST\ "
            id = self.tts.post.say(str(sentence))
            self.ids.append(id)
            self.tts.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                            <Parameter name="Voice shaping (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="150" tooltip='Used to modify at runtime the voice feature (tone, speed). In a slighty&#x0A;different way than pitch and speed, it gives a kind of &quot;gender or age&#x0A;modification&quot; effect.&#x0A;&#x0A;For instance, a quite good male derivation of female voice can be&#x0A;obtained setting this parameter to 78%.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the&#x0A;speed parameter. For example, if you want to decrease by 20% the voice&#x0A;shaping, you will have to increase by 20% the speed to keep a constant&#x0A;average speed.' id="5" />
                            <Parameter name="Speed (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="50" max="200" tooltip="Changes the speed of the voice.&#x0A;&#x0A;Note: For a better effect, you can compensate this parameter with the voice&#x0A;shaping parameter. For example, if you want to increase by 20% the speed, you&#x0A;will have to decrease by 20% the voice shaping to keep a constant average&#x0A;speed." id="6" />
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Fast STT - Eye Trigger (1)" id="45" localization="8" tooltip="Enter description here" x="305" y="1775">
                            <bitmap>media/images/box/box-diagram.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="Fast STT_onStart" type="1" type_size="1" nature="2" inner="0" tooltip="This input has been automatically generated&#x0A;by converting several boxes into a single box." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="" id="3" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Fast STT" id="47" localization="8" tooltip="Enter description here" x="209" y="54">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="This input has been automatically generated&#x0A;by converting several boxes into a single box." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="" id="3" />
                                                <Timeline enable="0">
                                                    <BehaviorLayer name="behavior_layer1">
                                                        <BehaviorKeyframe name="keyframe1" index="1">
                                                            <Diagram>
                                                                <Box name="Delay" id="34" localization="8" tooltip="Wait a moment before triggering the output. &#x0A;Can be stopped anytime. &#x0A;Multiple inputs will trigger multiple outputs." x="112" y="100">
                                                                    <bitmap>media/images/box/wait.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.delayed = []

    def onUnload(self):
        self.cancelDelays()

    def cancelDelays(self):
        cancel_list = list(self.delayed)
        for d in cancel_list:
            d.cancel()

    def cleanDelay(self, fut, fut_ref):
        self.delayed.remove(fut)

    def triggerOutput(self):
        self.timerOutput()

    def onInput_onStart(self):
        import qi
        import functools
        delay_future = qi.async(self.triggerOutput, delay=int(self.getParameter("Timeout (s)") * 1000 * 1000))
        # keep the async operation in an array for cancel
        # and remove it when it is finished in the callback
        self.delayed.append(delay_future)
        bound_clean = functools.partial(self.cleanDelay, delay_future)
        delay_future.addCallback(bound_clean)

    def onInput_onStop(self):
        if self.getParameter("Trigger timerOutput if cancelled") and self.delayed:
            self.timerOutput()
        self.onUnload()]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Start the Delay box with the configured timeout value." id="2" />
                                                                    <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stop the wait and stimulate the output." id="3" />
                                                                    <Output name="timerOutput" type="1" type_size="1" nature="1" inner="0" tooltip="Send a bang once delay set in parameters is elapsed, or if the box is stopped and the appropriate parameter is set." id="4" />
                                                                    <Parameter name="Timeout (s)" inherits_from_parent="0" content_type="2" value="0.9" default_value="1" min="0" max="5000" tooltip="Duration the box waits before stimulating the output." id="5" />
                                                                    <Parameter name="Trigger timerOutput if cancelled" inherits_from_parent="0" content_type="0" value="0" default_value="1" tooltip="If the box is currently delaying at least one signal and cancelled, output will be stimulated." id="6" />
                                                                </Box>
                                                                <Box name="Watson Listening Fast" id="48" localization="8" tooltip="This box makes the robot listen for human speech in English, and transcribes it. This is done by using the Bluemix Speech to Text (STT) service.&#x0A;&#x0A;Input: A signal to tell the box when to start listening.&#x0A;&#x0A;Output: A string of text, which is a transcription of what the robot heard." x="215" y="2">
                                                                    <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        self.watson = ALProxy('ALWatson')
        self.leds = ALProxy("ALLeds")


    def onUnload(self):
        pass

    def onInput_onStart(self):
        #id = self.leds.post.fadeRGB("FaceLeds",0,0,1, .7)
        #id = self.leds.post.fadeRGB("FaceLeds",0,0,0, .7)
        #id = self.leds.post.fadeRGB("FaceLeds",0,0,1, .7)
        #id = self.leds.post.fadeRGB("FaceLeds",0,0,0, .7)
        #id = self.leds.post.fadeRGB("FaceLeds",0,0,1, .7)
        #id = self.leds.post.fadeRGB("FaceLeds",0,0,0, .7)

        #while True:
        #    s = self.watson.stt_stream()
        #    self.logger.warning("SttStreamResult: {}".format(s))
        #    s_json = json.loads(s)




        s = self.watson.stt_stream()
        self.logger.info(s)
        s_json = json.loads(s)
        if "results" in s_json.keys():
            self.onStopped( str(s_json['results'][0]['alternatives'][0]['transcript']) )
        else:
            self.onStopped( "I think I had a bit of trouble hearing you. Could you say that again?" )




        #try:
        #    self.onStopped( str(s_json['results'][0]['alternatives'][0]['transcript']) )
        #    #self.leds.wait(id, 0)
        #except:
        #    self.logger.info("STT onError called")
        #    self.onError()]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="A signal to notify the box when it needs to start listening." id="2" />
                                                                    <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="A string of text that is the transcription of what the robot heard." id="3" />
                                                                    <Output name="onError" type="1" type_size="1" nature="1" inner="0" tooltip="" id="4" />
                                                                </Box>
                                                                <Box name="Eye LEDs" id="49" localization="8" tooltip="Set the LED color of the eyes. Note that you must open the box to enter the color." x="228" y="114">
                                                                    <bitmap>media/images/box/interaction/LED.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                                    <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                                                                    <Parameter name="Side" inherits_from_parent="0" content_type="3" value="Both" default_value="Both" custom_choice="0" tooltip="Choose the eye where the LED light is set." id="4">
                                                                        <Choice value="Both" />
                                                                        <Choice value="Left" />
                                                                        <Choice value="Right" />
                                                                    </Parameter>
                                                                    <Parameter name="Duration (s)" inherits_from_parent="0" content_type="2" value="1" default_value="0.1" min="0" max="5" tooltip="Transition&apos;s duration in seconds." id="5" />
                                                                    <Timeline enable="0">
                                                                        <BehaviorLayer name="behavior_layer1">
                                                                            <BehaviorKeyframe name="keyframe1" index="1">
                                                                                <Diagram>
                                                                                    <Box name="Eyes LEDs" id="15" localization="8" tooltip="Set the color of LEDs of robot&apos;s eyes." x="281" y="41">
                                                                                        <bitmap>media/images/box/interaction/LED.png</bitmap>
                                                                                        <script language="4">
                                                                                            <content>
                                                                                                <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.ids = []
        self.leds = ALProxy("ALLeds")

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_color(self, p):
        if( self.getParameter("Side") == "Left" ):
            sGroup = "LeftFaceLeds"
        elif( self.getParameter("Side") == "Right" ):
            sGroup = "RightFaceLeds"
        else:
            sGroup = "FaceLeds"
        id = self.leds.post.fadeRGB(sGroup, 256*256*p[0] + 256*p[1] + p[2], self.getParameter("Duration (s)"))
        self.ids.append(id)
        self.leds.wait(id, 0)
        self.ids.remove(id)
        if( self.ids == [] ):
            self.onDone() # activate output of the box]]>
</content>
                                                                                        </script>
                                                                                        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                                        <Input name="color" type="2" type_size="3" nature="2" inner="0" tooltip="Color of robot&apos;s eyes." id="2" />
                                                                                        <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                                                                                        <Parameter name="Side" inherits_from_parent="1" content_type="3" value="Both" default_value="Both" custom_choice="0" tooltip="Choose the eye where the LED light is set." id="4">
                                                                                            <Choice value="Both" />
                                                                                            <Choice value="Left" />
                                                                                            <Choice value="Right" />
                                                                                        </Parameter>
                                                                                        <Parameter name="Duration (s)" inherits_from_parent="1" content_type="2" value="0.1" default_value="0.1" min="0" max="5" tooltip="Transition&apos;s duration in seconds." id="5" />
                                                                                    </Box>
                                                                                    <Box name="Color Edit" id="16" localization="8" tooltip="Transmit a table of number [R,G,B] correponsding to the selected color." plugin="coloredit_plugin" x="105" y="47">
                                                                                        <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                                                        <script language="4">
                                                                                            <content>
                                                                                                <![CDATA[class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped([0, 81, 255])]]>
</content>
                                                                                        </script>
                                                                                        <pluginContent>
                                                                                            <color>#0051ff</color>
                                                                                        </pluginContent>
                                                                                        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                                        <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="To send the color on the output." id="2" />
                                                                                        <Output name="onStopped" type="2" type_size="3" nature="1" inner="0" tooltip="[R,G,B] with R, G and B between 0 and 255." id="3" />
                                                                                    </Box>
                                                                                    <Link inputowner="15" indexofinput="2" outputowner="16" indexofoutput="3" />
                                                                                    <Link inputowner="16" indexofinput="2" outputowner="0" indexofoutput="2" />
                                                                                    <Link inputowner="0" indexofinput="3" outputowner="15" indexofoutput="3" />
                                                                                </Diagram>
                                                                            </BehaviorKeyframe>
                                                                        </BehaviorLayer>
                                                                    </Timeline>
                                                                </Box>
                                                                <Link inputowner="34" indexofinput="2" outputowner="0" indexofoutput="2" />
                                                                <Link inputowner="48" indexofinput="2" outputowner="0" indexofoutput="2" />
                                                                <Link inputowner="0" indexofinput="3" outputowner="48" indexofoutput="3" />
                                                                <Link inputowner="49" indexofinput="2" outputowner="34" indexofoutput="4" />
                                                            </Diagram>
                                                        </BehaviorKeyframe>
                                                    </BehaviorLayer>
                                                </Timeline>
                                            </Box>
                                            <Box name="Normalize Eyes" id="54" localization="8" tooltip="Set the LED color of the eyes. Note that you must open the box to enter the color." x="344" y="49">
                                                <bitmap>media/images/box/interaction/LED.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                                                <Parameter name="Side" inherits_from_parent="0" content_type="3" value="Both" default_value="Both" custom_choice="0" tooltip="Choose the eye where the LED light is set." id="4">
                                                    <Choice value="Both" />
                                                    <Choice value="Left" />
                                                    <Choice value="Right" />
                                                </Parameter>
                                                <Parameter name="Duration (s)" inherits_from_parent="0" content_type="2" value="0.1" default_value="0.1" min="0" max="5" tooltip="Transition&apos;s duration in seconds." id="5" />
                                                <Timeline enable="0">
                                                    <BehaviorLayer name="behavior_layer1">
                                                        <BehaviorKeyframe name="keyframe1" index="1">
                                                            <Diagram>
                                                                <Box name="Eyes LEDs" id="15" localization="8" tooltip="Set the color of LEDs of robot&apos;s eyes." x="281" y="41">
                                                                    <bitmap>media/images/box/interaction/LED.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.ids = []
        self.leds = ALProxy("ALLeds")

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_color(self, p):
        if( self.getParameter("Side") == "Left" ):
            sGroup = "LeftFaceLeds"
        elif( self.getParameter("Side") == "Right" ):
            sGroup = "RightFaceLeds"
        else:
            sGroup = "FaceLeds"
        id = self.leds.post.fadeRGB(sGroup, 256*256*p[0] + 256*p[1] + p[2], self.getParameter("Duration (s)"))
        self.ids.append(id)
        self.leds.wait(id, 0)
        self.ids.remove(id)
        if( self.ids == [] ):
            self.onDone() # activate output of the box]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="color" type="2" type_size="3" nature="2" inner="0" tooltip="Color of robot&apos;s eyes." id="2" />
                                                                    <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                                                                    <Parameter name="Side" inherits_from_parent="1" content_type="3" value="Both" default_value="Both" custom_choice="0" tooltip="Choose the eye where the LED light is set." id="4">
                                                                        <Choice value="Both" />
                                                                        <Choice value="Left" />
                                                                        <Choice value="Right" />
                                                                    </Parameter>
                                                                    <Parameter name="Duration (s)" inherits_from_parent="1" content_type="2" value="0.1" default_value="0.1" min="0" max="5" tooltip="Transition&apos;s duration in seconds." id="5" />
                                                                </Box>
                                                                <Box name="Color Edit" id="16" localization="8" tooltip="Transmit a table of number [R,G,B] correponsding to the selected color." plugin="coloredit_plugin" x="105" y="47">
                                                                    <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped([255, 255, 255])]]>
</content>
                                                                    </script>
                                                                    <pluginContent>
                                                                        <color>#ffffff</color>
                                                                    </pluginContent>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="To send the color on the output." id="2" />
                                                                    <Output name="onStopped" type="2" type_size="3" nature="1" inner="0" tooltip="[R,G,B] with R, G and B between 0 and 255." id="3" />
                                                                </Box>
                                                                <Link inputowner="15" indexofinput="2" outputowner="16" indexofoutput="3" />
                                                                <Link inputowner="16" indexofinput="2" outputowner="0" indexofoutput="2" />
                                                                <Link inputowner="0" indexofinput="3" outputowner="15" indexofoutput="3" />
                                                            </Diagram>
                                                        </BehaviorKeyframe>
                                                    </BehaviorLayer>
                                                </Timeline>
                                            </Box>
                                            <Link inputowner="54" indexofinput="2" outputowner="47" indexofoutput="3" />
                                            <Link inputowner="47" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="0" indexofinput="3" outputowner="47" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                        </Box>
                        <Box name="Fast STT - Eye Trigger" id="47" localization="8" tooltip="Enter description here" x="322" y="1656">
                            <bitmap>media/images/box/box-diagram.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="Fast STT_onStart" type="1" type_size="1" nature="2" inner="0" tooltip="This input has been automatically generated&#x0A;by converting several boxes into a single box." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="" id="3" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Fast STT" id="47" localization="8" tooltip="Enter description here" x="209" y="54">
                                                <bitmap>media/images/box/box-diagram.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="This input has been automatically generated&#x0A;by converting several boxes into a single box." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="" id="3" />
                                                <Timeline enable="0">
                                                    <BehaviorLayer name="behavior_layer1">
                                                        <BehaviorKeyframe name="keyframe1" index="1">
                                                            <Diagram>
                                                                <Box name="Delay" id="34" localization="8" tooltip="Wait a moment before triggering the output. &#x0A;Can be stopped anytime. &#x0A;Multiple inputs will trigger multiple outputs." x="112" y="100">
                                                                    <bitmap>media/images/box/wait.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.delayed = []

    def onUnload(self):
        self.cancelDelays()

    def cancelDelays(self):
        cancel_list = list(self.delayed)
        for d in cancel_list:
            d.cancel()

    def cleanDelay(self, fut, fut_ref):
        self.delayed.remove(fut)

    def triggerOutput(self):
        self.timerOutput()

    def onInput_onStart(self):
        import qi
        import functools
        delay_future = qi.async(self.triggerOutput, delay=int(self.getParameter("Timeout (s)") * 1000 * 1000))
        # keep the async operation in an array for cancel
        # and remove it when it is finished in the callback
        self.delayed.append(delay_future)
        bound_clean = functools.partial(self.cleanDelay, delay_future)
        delay_future.addCallback(bound_clean)

    def onInput_onStop(self):
        if self.getParameter("Trigger timerOutput if cancelled") and self.delayed:
            self.timerOutput()
        self.onUnload()]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Start the Delay box with the configured timeout value." id="2" />
                                                                    <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stop the wait and stimulate the output." id="3" />
                                                                    <Output name="timerOutput" type="1" type_size="1" nature="1" inner="0" tooltip="Send a bang once delay set in parameters is elapsed, or if the box is stopped and the appropriate parameter is set." id="4" />
                                                                    <Parameter name="Timeout (s)" inherits_from_parent="0" content_type="2" value="0.9" default_value="1" min="0" max="5000" tooltip="Duration the box waits before stimulating the output." id="5" />
                                                                    <Parameter name="Trigger timerOutput if cancelled" inherits_from_parent="0" content_type="0" value="0" default_value="1" tooltip="If the box is currently delaying at least one signal and cancelled, output will be stimulated." id="6" />
                                                                </Box>
                                                                <Box name="Watson Listening Fast" id="48" localization="8" tooltip="This box makes the robot listen for human speech in English, and transcribes it. This is done by using the Bluemix Speech to Text (STT) service.&#x0A;&#x0A;Input: A signal to tell the box when to start listening.&#x0A;&#x0A;Output: A string of text, which is a transcription of what the robot heard." x="215" y="2">
                                                                    <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        self.watson = ALProxy('ALWatson')
        self.leds = ALProxy("ALLeds")


    def onUnload(self):
        pass

    def onInput_onStart(self):
        #id = self.leds.post.fadeRGB("FaceLeds",0,0,1, .7)
        #id = self.leds.post.fadeRGB("FaceLeds",0,0,0, .7)
        #id = self.leds.post.fadeRGB("FaceLeds",0,0,1, .7)
        #id = self.leds.post.fadeRGB("FaceLeds",0,0,0, .7)
        #id = self.leds.post.fadeRGB("FaceLeds",0,0,1, .7)
        #id = self.leds.post.fadeRGB("FaceLeds",0,0,0, .7)

        #while True:
        #    s = self.watson.stt_stream()
        #    self.logger.warning("SttStreamResult: {}".format(s))
        #    s_json = json.loads(s)




        s = self.watson.stt_stream()
        self.logger.info(s)
        s_json = json.loads(s)
        if "results" in s_json.keys():
            self.onStopped( str(s_json['results'][0]['alternatives'][0]['transcript']) )
        else:
            self.onStopped( "I think I had a bit of trouble hearing you. Could you say that again?" )




        #try:
        #    self.onStopped( str(s_json['results'][0]['alternatives'][0]['transcript']) )
        #    #self.leds.wait(id, 0)
        #except:
        #    self.logger.info("STT onError called")
        #    self.onError()]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="A signal to notify the box when it needs to start listening." id="2" />
                                                                    <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="A string of text that is the transcription of what the robot heard." id="3" />
                                                                    <Output name="onError" type="1" type_size="1" nature="1" inner="0" tooltip="" id="4" />
                                                                </Box>
                                                                <Box name="Eye LEDs" id="49" localization="8" tooltip="Set the LED color of the eyes. Note that you must open the box to enter the color." x="228" y="114">
                                                                    <bitmap>media/images/box/interaction/LED.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                                    <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                                                                    <Parameter name="Side" inherits_from_parent="0" content_type="3" value="Both" default_value="Both" custom_choice="0" tooltip="Choose the eye where the LED light is set." id="4">
                                                                        <Choice value="Both" />
                                                                        <Choice value="Left" />
                                                                        <Choice value="Right" />
                                                                    </Parameter>
                                                                    <Parameter name="Duration (s)" inherits_from_parent="0" content_type="2" value="1" default_value="0.1" min="0" max="5" tooltip="Transition&apos;s duration in seconds." id="5" />
                                                                    <Timeline enable="0">
                                                                        <BehaviorLayer name="behavior_layer1">
                                                                            <BehaviorKeyframe name="keyframe1" index="1">
                                                                                <Diagram>
                                                                                    <Box name="Eyes LEDs" id="15" localization="8" tooltip="Set the color of LEDs of robot&apos;s eyes." x="281" y="41">
                                                                                        <bitmap>media/images/box/interaction/LED.png</bitmap>
                                                                                        <script language="4">
                                                                                            <content>
                                                                                                <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.ids = []
        self.leds = ALProxy("ALLeds")

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_color(self, p):
        if( self.getParameter("Side") == "Left" ):
            sGroup = "LeftFaceLeds"
        elif( self.getParameter("Side") == "Right" ):
            sGroup = "RightFaceLeds"
        else:
            sGroup = "FaceLeds"
        id = self.leds.post.fadeRGB(sGroup, 256*256*p[0] + 256*p[1] + p[2], self.getParameter("Duration (s)"))
        self.ids.append(id)
        self.leds.wait(id, 0)
        self.ids.remove(id)
        if( self.ids == [] ):
            self.onDone() # activate output of the box]]>
</content>
                                                                                        </script>
                                                                                        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                                        <Input name="color" type="2" type_size="3" nature="2" inner="0" tooltip="Color of robot&apos;s eyes." id="2" />
                                                                                        <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                                                                                        <Parameter name="Side" inherits_from_parent="1" content_type="3" value="Both" default_value="Both" custom_choice="0" tooltip="Choose the eye where the LED light is set." id="4">
                                                                                            <Choice value="Both" />
                                                                                            <Choice value="Left" />
                                                                                            <Choice value="Right" />
                                                                                        </Parameter>
                                                                                        <Parameter name="Duration (s)" inherits_from_parent="1" content_type="2" value="0.1" default_value="0.1" min="0" max="5" tooltip="Transition&apos;s duration in seconds." id="5" />
                                                                                    </Box>
                                                                                    <Box name="Color Edit" id="16" localization="8" tooltip="Transmit a table of number [R,G,B] correponsding to the selected color." plugin="coloredit_plugin" x="105" y="47">
                                                                                        <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                                                        <script language="4">
                                                                                            <content>
                                                                                                <![CDATA[class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped([0, 81, 255])]]>
</content>
                                                                                        </script>
                                                                                        <pluginContent>
                                                                                            <color>#0051ff</color>
                                                                                        </pluginContent>
                                                                                        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                                        <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="To send the color on the output." id="2" />
                                                                                        <Output name="onStopped" type="2" type_size="3" nature="1" inner="0" tooltip="[R,G,B] with R, G and B between 0 and 255." id="3" />
                                                                                    </Box>
                                                                                    <Link inputowner="15" indexofinput="2" outputowner="16" indexofoutput="3" />
                                                                                    <Link inputowner="16" indexofinput="2" outputowner="0" indexofoutput="2" />
                                                                                    <Link inputowner="0" indexofinput="3" outputowner="15" indexofoutput="3" />
                                                                                </Diagram>
                                                                            </BehaviorKeyframe>
                                                                        </BehaviorLayer>
                                                                    </Timeline>
                                                                </Box>
                                                                <Link inputowner="34" indexofinput="2" outputowner="0" indexofoutput="2" />
                                                                <Link inputowner="48" indexofinput="2" outputowner="0" indexofoutput="2" />
                                                                <Link inputowner="0" indexofinput="3" outputowner="48" indexofoutput="3" />
                                                                <Link inputowner="49" indexofinput="2" outputowner="34" indexofoutput="4" />
                                                            </Diagram>
                                                        </BehaviorKeyframe>
                                                    </BehaviorLayer>
                                                </Timeline>
                                            </Box>
                                            <Box name="Normalize Eyes" id="54" localization="8" tooltip="Set the LED color of the eyes. Note that you must open the box to enter the color." x="344" y="49">
                                                <bitmap>media/images/box/interaction/LED.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                                                <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                                                <Parameter name="Side" inherits_from_parent="0" content_type="3" value="Both" default_value="Both" custom_choice="0" tooltip="Choose the eye where the LED light is set." id="4">
                                                    <Choice value="Both" />
                                                    <Choice value="Left" />
                                                    <Choice value="Right" />
                                                </Parameter>
                                                <Parameter name="Duration (s)" inherits_from_parent="0" content_type="2" value="0.1" default_value="0.1" min="0" max="5" tooltip="Transition&apos;s duration in seconds." id="5" />
                                                <Timeline enable="0">
                                                    <BehaviorLayer name="behavior_layer1">
                                                        <BehaviorKeyframe name="keyframe1" index="1">
                                                            <Diagram>
                                                                <Box name="Eyes LEDs" id="15" localization="8" tooltip="Set the color of LEDs of robot&apos;s eyes." x="281" y="41">
                                                                    <bitmap>media/images/box/interaction/LED.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.ids = []
        self.leds = ALProxy("ALLeds")

    def onUnload(self):
        #~ puts code for box cleanup here
        pass

    def onInput_color(self, p):
        if( self.getParameter("Side") == "Left" ):
            sGroup = "LeftFaceLeds"
        elif( self.getParameter("Side") == "Right" ):
            sGroup = "RightFaceLeds"
        else:
            sGroup = "FaceLeds"
        id = self.leds.post.fadeRGB(sGroup, 256*256*p[0] + 256*p[1] + p[2], self.getParameter("Duration (s)"))
        self.ids.append(id)
        self.leds.wait(id, 0)
        self.ids.remove(id)
        if( self.ids == [] ):
            self.onDone() # activate output of the box]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="color" type="2" type_size="3" nature="2" inner="0" tooltip="Color of robot&apos;s eyes." id="2" />
                                                                    <Output name="onDone" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                                                                    <Parameter name="Side" inherits_from_parent="1" content_type="3" value="Both" default_value="Both" custom_choice="0" tooltip="Choose the eye where the LED light is set." id="4">
                                                                        <Choice value="Both" />
                                                                        <Choice value="Left" />
                                                                        <Choice value="Right" />
                                                                    </Parameter>
                                                                    <Parameter name="Duration (s)" inherits_from_parent="1" content_type="2" value="0.1" default_value="0.1" min="0" max="5" tooltip="Transition&apos;s duration in seconds." id="5" />
                                                                </Box>
                                                                <Box name="Color Edit" id="16" localization="8" tooltip="Transmit a table of number [R,G,B] correponsding to the selected color." plugin="coloredit_plugin" x="105" y="47">
                                                                    <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped([255, 255, 255])]]>
</content>
                                                                    </script>
                                                                    <pluginContent>
                                                                        <color>#ffffff</color>
                                                                    </pluginContent>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="To send the color on the output." id="2" />
                                                                    <Output name="onStopped" type="2" type_size="3" nature="1" inner="0" tooltip="[R,G,B] with R, G and B between 0 and 255." id="3" />
                                                                </Box>
                                                                <Link inputowner="15" indexofinput="2" outputowner="16" indexofoutput="3" />
                                                                <Link inputowner="16" indexofinput="2" outputowner="0" indexofoutput="2" />
                                                                <Link inputowner="0" indexofinput="3" outputowner="15" indexofoutput="3" />
                                                            </Diagram>
                                                        </BehaviorKeyframe>
                                                    </BehaviorLayer>
                                                </Timeline>
                                            </Box>
                                            <Link inputowner="54" indexofinput="2" outputowner="47" indexofoutput="3" />
                                            <Link inputowner="47" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="0" indexofinput="3" outputowner="47" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                        </Box>
                        <Box name="Fast STT - Sound Trigger" id="39" localization="8" tooltip="Enter description here" x="868" y="1458">
                            <bitmap>media/images/box/box-diagram.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="This input has been automatically generated&#x0A;by converting several boxes into a single box." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="" id="3" />
                            <Timeline enable="0">
                                <BehaviorLayer name="behavior_layer1">
                                    <BehaviorKeyframe name="keyframe1" index="1">
                                        <Diagram>
                                            <Box name="Watson Listening Fast (3)" id="37" localization="8" tooltip="This box makes the robot listen for human speech in English, and transcribes it. This is done by using the Bluemix Speech to Text (STT) service.&#x0A;&#x0A;Input: A signal to tell the box when to start listening.&#x0A;&#x0A;Output: A string of text, which is a transcription of what the robot heard." x="230" y="5">
                                                <bitmap>media/images/box/watson-lib-icons/speech_icon.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        self.watson = ALProxy('ALWatson')
        self.leds = ALProxy("ALLeds")


    def onUnload(self):
        pass

    def onInput_onStart(self):

        #id = self.leds.post.fadeRGB("FaceLeds",20991, .7)
        #while True:
        #    s = self.watson.stt_stream()
        #    self.logger.warning("SttStreamResult: {}".format(s))
        #    s_json = json.loads(s)

        while True:
            s = self.watson.stt_stream()
            self.logger.warning("SttStreamResult: {}".format(s))
            s_json = json.loads(s)
            if "state" in s_json.keys():
                #print "state"
                pass
            elif "results" in s_json.keys():
                self.onStopped( str(s_json['results'][0]['alternatives'][0]['transcript']) )
                break



        #try:
        #    self.onStopped( str(s_json['results'][0]['alternatives'][0]['transcript']) )
        #    #self.leds.wait(id, 0)
        #except:
        #    self.logger.info("STT onError called")
        #    self.onError()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="A signal to notify the box when it needs to start listening." id="2" />
                                                <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="A string of text that is the transcription of what the robot heard." id="3" />
                                                <Output name="onError" type="1" type_size="1" nature="1" inner="0" tooltip="" id="4" />
                                            </Box>
                                            <Box name="Play Sound" id="40" localization="8" tooltip="Play a sound file. Select the file in parameters. The format of the file can be wav or ogg (on virtual robot) and also mp3 (on a real robot).&#x0A;&#x0A;Note: There can be some delay to play ogg or mp3 (on a robot) files. We advise you to use wav if&#x0A;you want a fast play of the file." x="231" y="100">
                                                <bitmap>media/images/box/interaction/play_music.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.bIsRunning = False

    def onUnload(self):
        self.bIsRunning = False

    def onInput_onStart(self):
        self.bIsRunning = True

    def onInput_onStop(self):
        if( self.bIsRunning ):
            self.onUnload()
            self.onStopped()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Starts the music." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stops the music." id="3" />
                                                <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished or stopped." id="4" />
                                                <Parameter name="File name" inherits_from_parent="0" content_type="4" value="/../Ding Sound Effect.mp3" default_value="" tooltip="Name of the file you want to play.&#x0A;&#x0A;Note: You can click on the folder icon to browse the project content or import&#x0A;new files to the project." id="5" />
                                                <Parameter name="Begin position (s)" inherits_from_parent="0" content_type="2" value="0" default_value="0" min="0" max="600" tooltip="Position in seconds where the playing must start." id="6" />
                                                <Parameter name="Volume (%)" inherits_from_parent="0" content_type="1" value="60" default_value="100" min="0" max="100" tooltip="Volume the file is played with." id="7" />
                                                <Parameter name="Balance L/R" inherits_from_parent="0" content_type="2" value="0" default_value="0" min="-1" max="1" tooltip="Value which determines if the sound is played more on the robot&apos;s left or right.&#x0A;You can particularly set it to:&#x0A;- -1 to play only on the left loudspeaker.&#x0A;- 0 to play on both loudspeakers.&#x0A;- 1 to play only on the right loudspeaker." id="8" />
                                                <Parameter name="Play in loop" inherits_from_parent="0" content_type="0" value="0" default_value="0" tooltip="This parameter allows to play the file in loop. The playing will start each time at&#x0A;the beginning of the file." id="9" />
                                                <Timeline enable="0">
                                                    <BehaviorLayer name="behavior_layer1">
                                                        <BehaviorKeyframe name="keyframe1" index="1">
                                                            <Diagram>
                                                                <Box name="Play Sound File" id="2" localization="8" tooltip="Play the sound." x="442" y="70">
                                                                    <bitmap>media/images/box/interaction/play_music.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.player = ALProxy('ALAudioPlayer')
        self.playerStop = ALProxy('ALAudioPlayer', True) #Create another proxy as wait is blocking if audioout is remote

    def onLoad(self):
        self.bIsRunning = False
        self.ids = []

    def onUnload(self):
        for id in self.ids:
            try:
                self.playerStop.stop(id)
            except:
                pass
        while( self.bIsRunning ):
            time.sleep( 0.2 )

    def onInput_onStart(self, p):
        self.bIsRunning = True
        try:
            if (self.getParameter("Play in loop")) :
               id = self.player.post.playFileInLoop(p,self.getParameter("Volume (%)")/100.,self.getParameter("Balance L/R"))
            else :
               id = self.player.post.playFileFromPosition(p,self.getParameter("Begin position (s)"),self.getParameter("Volume (%)")/100.,self.getParameter("Balance L/R"))
            self.ids.append(id)
            self.player.wait(id, 0)
        finally:
            try:
                self.ids.remove(id)
            except:
                pass
            if( self.ids == [] ):
                self.onStopped() # activate output of the box
                self.bIsRunning = False

    def onInput_onStop(self):
        self.onUnload()]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this Input." id="2" />
                                                                    <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this Input." id="3" />
                                                                    <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when Box behavior is finished." id="4" />
                                                                    <Parameter name="Begin position (s)" inherits_from_parent="1" content_type="2" value="0" default_value="0" min="0" max="600" tooltip="Position in seconds where the playing must start." id="5" />
                                                                    <Parameter name="Volume (%)" inherits_from_parent="1" content_type="1" value="100" default_value="100" min="0" max="100" tooltip="Volume the file is played with." id="6" />
                                                                    <Parameter name="Balance L/R" inherits_from_parent="1" content_type="2" value="0" default_value="0" min="-1" max="1" tooltip="Value which determines if the sound is played more on the robot&apos;s left or right.&#x0A;You can particularly set it to:&#x0A;- -1 to play only on the left loudspeaker.&#x0A;- 0 to play on both loudspeakers.&#x0A;- 1 to play only on the right loudspeaker." id="7" />
                                                                    <Parameter name="Play in loop" inherits_from_parent="1" content_type="0" value="0" default_value="0" tooltip="This parameter allows to play the file in loop. The playing will start each time at&#x0A;the beginning of the file." id="8" />
                                                                </Box>
                                                                <Box name="Get Attached File" id="1" localization="8" tooltip="Use this box to choose an attached file in its parameters. The filename will be sent on&#x0A;the output when the input is stimulated." x="216" y="71">
                                                                    <bitmap>media/images/box/folder.png</bitmap>
                                                                    <script language="4">
                                                                        <content>
                                                                            <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.framemanager = ALProxy("ALFrameManager")

    def onInput_onStart(self):
        self.onStopped(self.framemanager.getBehaviorPath(self.behaviorId) + self.getParameter("File name"))]]>
</content>
                                                                    </script>
                                                                    <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                                    <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the filepath on the output." id="2" />
                                                                    <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The filepath of the selected resource file." id="3" />
                                                                    <Parameter name="File name" inherits_from_parent="1" content_type="4" value="" default_value="" tooltip="Name of the file which is going to be sent on the box output.&#x0A;&#x0A;Note: You can click on the folder icon to browse the project content or import&#x0A;new files to the project." id="4" />
                                                                </Box>
                                                                <Link inputowner="0" indexofinput="4" outputowner="2" indexofoutput="4" />
                                                                <Link inputowner="1" indexofinput="2" outputowner="0" indexofoutput="2" />
                                                                <Link inputowner="2" indexofinput="2" outputowner="1" indexofoutput="3" />
                                                            </Diagram>
                                                        </BehaviorKeyframe>
                                                    </BehaviorLayer>
                                                </Timeline>
                                                <Resource name="Audio player" type="Lock" timeout="0" />
                                            </Box>
                                            <Box name="Delay" id="34" localization="8" tooltip="Wait a moment before triggering the output. &#x0A;Can be stopped anytime. &#x0A;Multiple inputs will trigger multiple outputs." x="111" y="92">
                                                <bitmap>media/images/box/wait.png</bitmap>
                                                <script language="4">
                                                    <content>
                                                        <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        self.delayed = []

    def onUnload(self):
        self.cancelDelays()

    def cancelDelays(self):
        cancel_list = list(self.delayed)
        for d in cancel_list:
            d.cancel()

    def cleanDelay(self, fut, fut_ref):
        self.delayed.remove(fut)

    def triggerOutput(self):
        self.timerOutput()

    def onInput_onStart(self):
        import qi
        import functools
        delay_future = qi.async(self.triggerOutput, delay=int(self.getParameter("Timeout (s)") * 1000 * 1000))
        # keep the async operation in an array for cancel
        # and remove it when it is finished in the callback
        self.delayed.append(delay_future)
        bound_clean = functools.partial(self.cleanDelay, delay_future)
        delay_future.addCallback(bound_clean)

    def onInput_onStop(self):
        if self.getParameter("Trigger timerOutput if cancelled") and self.delayed:
            self.timerOutput()
        self.onUnload()]]>
</content>
                                                </script>
                                                <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                                                <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Start the Delay box with the configured timeout value." id="2" />
                                                <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Stop the wait and stimulate the output." id="3" />
                                                <Output name="timerOutput" type="1" type_size="1" nature="1" inner="0" tooltip="Send a bang once delay set in parameters is elapsed, or if the box is stopped and the appropriate parameter is set." id="4" />
                                                <Parameter name="Timeout (s)" inherits_from_parent="0" content_type="2" value="0.7" default_value="1" min="0" max="5000" tooltip="Duration the box waits before stimulating the output." id="5" />
                                                <Parameter name="Trigger timerOutput if cancelled" inherits_from_parent="0" content_type="0" value="0" default_value="1" tooltip="If the box is currently delaying at least one signal and cancelled, output will be stimulated." id="6" />
                                            </Box>
                                            <Link inputowner="40" indexofinput="2" outputowner="34" indexofoutput="4" />
                                            <Link inputowner="37" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="34" indexofinput="2" outputowner="0" indexofoutput="2" />
                                            <Link inputowner="0" indexofinput="3" outputowner="37" indexofoutput="3" />
                                        </Diagram>
                                    </BehaviorKeyframe>
                                </BehaviorLayer>
                            </Timeline>
                        </Box>
                        <Box name="Set Language (1)" id="26" localization="8" tooltip="Select the language you would like the robot to speak and understand. Any following call to&#x0A;ALSpeechRecognition (Speech Reco. box for instance) or ALTextToSpeech (Say box&#x0A;for instance) will use this language." x="3" y="887">
                            <bitmap>media/images/box/interaction/say.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)

    def onLoad(self):
        try:
            self.tts = ALProxy("ALTextToSpeech")
        except:
            self.logger.warn("ALTextToSpeech is not available, language setting cannot be applied to speech")
            self.tts = None

        try:
            self.asr = ALProxy("ALSpeechRecognition")
        except:
            self.logger.warn("ALSpeechRecognition is not available, language setting cannot be applied to recognition")
            self.asr = None

        try:
            self.dialog = ALProxy("ALDialog")
        except:
            self.logger.warn("ALDialog is not available, language setting cannot be applied to dialog")
            self.dialog = None

    def onInput_onSet(self):
        lang = self.getParameter("Language")
        try:
            if self.asr:
                self.asr.setLanguage( self.getParameter("Language") )
            if self.tts:
                self.tts.setLanguage( self.getParameter("Language") )
            if self.dialog:
                self.dialog.setLanguage( self.getParameter("Language") )
            if self.tts is None and self.asr is None and self.dialog is None:
                raise RuntimeError("Cannot set language: neither ALTextToSpeech nor ALSpeechRecognition nor ALDialog is available.")
            self.onReady()
        except:
            error = "Language " + lang + " cannot be set."
            self.logger.warn(error)
            self.onError(error)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onSet" type="1" type_size="1" nature="1" inner="0" tooltip="The data is set when a signal is received on this input." id="2" />
                            <Output name="onReady" type="1" type_size="1" nature="2" inner="0" tooltip="Signal sent when the data has been set." id="3" />
                            <Output name="onError" type="3" type_size="1" nature="2" inner="0" tooltip="Error output:&#x0A;- triggered if the language asked cannot be set" id="4" />
                            <Parameter name="Language" inherits_from_parent="0" content_type="3" value="English" default_value="English" custom_choice="1" tooltip="Set the language the robot speaks and understands." id="5">
                                <Choice value="Arabic" />
                                <Choice value="Brazilian" />
                                <Choice value="Chinese" />
                                <Choice value="Czech" />
                                <Choice value="Danish" />
                                <Choice value="Dutch" />
                                <Choice value="English" />
                                <Choice value="Finnish" />
                                <Choice value="French" />
                                <Choice value="German" />
                                <Choice value="Italian" />
                                <Choice value="Japanese" />
                                <Choice value="Korean" />
                                <Choice value="Polish" />
                                <Choice value="Portuguese" />
                                <Choice value="Russian" />
                                <Choice value="Spanish" />
                                <Choice value="Swedish" />
                                <Choice value="Turkish" />
                            </Parameter>
                            <Resource name="Speech" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Natural Language Classify" id="28" localization="8" tooltip="This box uses Personality Insights, the Bluemix service designed to identify the personality of a person by analyzing a block of text written/spoken by the person. Personality Insights requires a minimum of 100 words, but suggests upwords of 2000 words.&#x0A;&#x0A;Input: The block of English text used to analyze a personality. Minimun 100 words, but 2000+ words suggested.&#x0A;&#x0A;Output: The raw json file which holds the analysis." x="308" y="1883">
                            <bitmap>media/images/box/watson-lib-icons/log_icon.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import json

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.watson = ALProxy('ALWatson')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self, p):
        nlc_data = self.watson.natural_language_classify(p, None, None)
        self.logger.info(nlc_data)
        #self.logger.info(json.loads(nlc_data))
        self.onStopped(nlc_data) #activate the output of the box
        pass]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="3" type_size="1" nature="2" inner="0" tooltip="Input the block of English text used to analyze a personality. Need at least 100 words, but for best results, Bluemix suggests at least 2000 words." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="1" inner="0" tooltip="A large data file (json) is the output of this box. This file holds personailty traits and their corresponding percentages; this shows how applicable they are to the given personality" id="3" />
                        </Box>
                        <Box name="Text Edit (9)" id="48" localization="8" tooltip="Send the text you entered when the input is stimulated." plugin="textedit_plugin" x="57" y="1890">
                            <bitmap>media/images/box/interaction/vocabulary.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# /!\ Generated content. Do not edit!
class MyClass(GeneratedClass):
	def __init__(self):
		GeneratedClass.__init__(self)

	def onInput_onStart(self):
		self.onStopped("How are you?")]]>
</content>
                            </script>
                            <pluginContent>
                                <text>
                                    <![CDATA[How are you?]]>
</text>
                            </pluginContent>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when Diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="1" inner="0" tooltip="To send the text on the output." id="2" />
                            <Output name="onStopped" type="3" type_size="1" nature="2" inner="0" tooltip="The text you entered." id="3" />
                        </Box>
                        <Link inputowner="0" indexofinput="4" outputowner="4" indexofoutput="3" />
                        <Link inputowner="2" indexofinput="2" outputowner="1" indexofoutput="3" />
                        <Link inputowner="2" indexofinput="2" outputowner="6" indexofoutput="3" />
                        <Link inputowner="2" indexofinput="2" outputowner="11" indexofoutput="3" />
                        <Link inputowner="2" indexofinput="2" outputowner="9" indexofoutput="3" />
                        <Link inputowner="2" indexofinput="2" outputowner="14" indexofoutput="3" />
                        <Link inputowner="2" indexofinput="2" outputowner="18" indexofoutput="3" />
                        <Link inputowner="2" indexofinput="2" outputowner="16" indexofoutput="3" />
                        <Link inputowner="7" indexofinput="2" outputowner="3" indexofoutput="3" />
                        <Link inputowner="18" indexofinput="2" outputowner="13" indexofoutput="3" />
                        <Link inputowner="14" indexofinput="2" outputowner="12" indexofoutput="3" />
                        <Link inputowner="9" indexofinput="2" outputowner="10" indexofoutput="3" />
                        <Link inputowner="11" indexofinput="2" outputowner="8" indexofoutput="3" />
                        <Link inputowner="16" indexofinput="2" outputowner="15" indexofoutput="3" />
                        <Link inputowner="21" indexofinput="2" outputowner="17" indexofoutput="3" />
                        <Link inputowner="21" indexofinput="2" outputowner="19" indexofoutput="3" />
                        <Link inputowner="19" indexofinput="2" outputowner="23" indexofoutput="3" />
                        <Link inputowner="0" indexofinput="4" outputowner="21" indexofoutput="4" />
                        <Link inputowner="21" indexofinput="2" outputowner="20" indexofoutput="3" />
                        <Link inputowner="4" indexofinput="2" outputowner="5" indexofoutput="3" />
                        <Link inputowner="24" indexofinput="2" outputowner="2" indexofoutput="4" />
                        <Link inputowner="0" indexofinput="4" outputowner="24" indexofoutput="3" />
                        <Link inputowner="4" indexofinput="2" outputowner="25" indexofoutput="3" />
                        <Link inputowner="17" indexofinput="2" outputowner="22" indexofoutput="3" />
                        <Link inputowner="2" indexofinput="2" outputowner="7" indexofoutput="3" />
                        <Link inputowner="32" indexofinput="2" outputowner="31" indexofoutput="3" />
                        <Link inputowner="33" indexofinput="2" outputowner="32" indexofoutput="3" />
                        <Link inputowner="0" indexofinput="4" outputowner="33" indexofoutput="4" />
                        <Link inputowner="31" indexofinput="2" outputowner="27" indexofoutput="3" />
                        <Link inputowner="36" indexofinput="2" outputowner="35" indexofoutput="3" />
                        <Link inputowner="38" indexofinput="2" outputowner="30" indexofoutput="4" />
                        <Link inputowner="29" indexofinput="2" outputowner="38" indexofoutput="4" />
                        <Link inputowner="35" indexofinput="2" outputowner="29" indexofoutput="3" />
                        <Link inputowner="29" indexofinput="2" outputowner="36" indexofoutput="4" />
                        <Link inputowner="41" indexofinput="2" outputowner="40" indexofoutput="3" />
                        <Link inputowner="43" indexofinput="2" outputowner="34" indexofoutput="4" />
                        <Link inputowner="46" indexofinput="2" outputowner="44" indexofoutput="4" />
                        <Link inputowner="45" indexofinput="2" outputowner="43" indexofoutput="4" />
                        <Link inputowner="44" indexofinput="2" outputowner="45" indexofoutput="3" />
                        <Link inputowner="45" indexofinput="2" outputowner="46" indexofoutput="4" />
                        <Link inputowner="40" indexofinput="2" outputowner="47" indexofoutput="3" />
                        <Link inputowner="47" indexofinput="2" outputowner="42" indexofoutput="4" />
                        <Link inputowner="47" indexofinput="2" outputowner="41" indexofoutput="4" />
                        <Link inputowner="42" indexofinput="2" outputowner="37" indexofoutput="3" />
                        <Link inputowner="22" indexofinput="2" outputowner="26" indexofoutput="3" />
                        <Link inputowner="28" indexofinput="2" outputowner="48" indexofoutput="3" />
                        <Link inputowner="0" indexofinput="4" outputowner="28" indexofoutput="3" />
                    </Diagram>
                </BehaviorKeyframe>
            </BehaviorLayer>
        </Timeline>
    </Box>
</ChoregrapheProject>
